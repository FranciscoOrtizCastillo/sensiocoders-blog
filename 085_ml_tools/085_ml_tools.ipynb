{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/085_ml_tools/085_ml_tools.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías de Python para ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el post anterior arrancamos con la serie sobre `Machine Learning`, en la que veremos múltiples algoritmos desarrollados durante las últimas décadas y que podemos usar como alternativa a las `redes neuronales` (*deep learning*), en algunos casos obteniendo mejores resultados (sobretodo en aquellos casos en los que no dispongamos de un dataset grande). Sin embargo, antes de entrar con los algoritmos y aplicaciones, vamos a hablar sobre el ecosistema de librerías existentes en `Python` para el `Machine Learning`, haciendo hincapié en aquellas más usadas por la comunidad y que también utilizaremos en esta serie.\n",
    "\n",
    "![](./tools.png)\n",
    "\n",
    "En la imagen anterior puedes ver un resumen de las herramientas más usadas a día de hoy para `Machine Learning` con `Python`. Las herramientas rodeadas por un círculo rojo son las que usaremos en esta serie, en verde son herramientas para `deep learning` que no usaremos (pero hemos usado en otros posts). Las herramientas sin círculo no las usaremos, pero vale la pena conocerlas ya que pueden serte útiles para algunas aplicaciones. \n",
    "\n",
    "En la base podemos encontrar `Python`, el lenguaje de programación base que todas las herramientas utilizan. Por encima encontramos herramientas como `Numpy`, para cálculo numérico, o `Jupyter`, para ejecutar nuestro código en `notebooks`. Por encima vemos herramientas basadas en `Numpy` como `Pandas`, para trabajar con datos tabulares, y `Matplotlib`, para generar gráficos en `Python`. Finalmente, en la última capa, encontramos `Scikit-Learn`, una de las librerías más utilizadas hoy en día para entrenar modelos de `Machine Learning`.\n",
    "\n",
    "> En este blog ya hemos dedicado posts a todas estas librerías, excepto a `Scikit-Learn`. Te recomiendo especialmente, si no conoces estas librerías, mi curso gratuito de [Análisis de Datos](https://juansensio.com/da-yt) en las que aprenderas sobre ellas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resto de este post lo vamos a dedicar a introducir los conceptos más importantes de [Scikit-Learn](https://scikit-learn.org/stable/), y que desarrollaremos durante la serie. Puedes empezar por instalar la librería\n",
    "\n",
    "```\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "Y seguir echando un vistazo a la [documentación](https://scikit-learn.org/stable/getting_started.html) y [ejemplos](https://scikit-learn.org/stable/auto_examples/index.html). \n",
    "\n",
    "En cualquier proyecto de `Machine Learning` deberemos seguir una serie de pasos, los cuales describiremos al final de la serie. En lo referente al entrenamiento de modelos, normalmente encontramos tres pasos:\n",
    "\n",
    "1. Preparar los datos\n",
    "2. Entrenar modelos\n",
    "3. Optimizar hyperparámetros\n",
    "\n",
    "Existen otros pasos igual o más de importantes, pero (repito) los veremos más adelante ya que no involucran el uso de `Scikit-Learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejemplo vamos a utilizar un dataset para predicción de precios de casas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "\n",
    "URL = \"https://mymldatasets.s3.eu-de.cloud-object-storage.appdomain.cloud/housing.tgz\"\n",
    "PATH = \"housing.tgz\"\n",
    "\n",
    "def getData(url=URL, path=PATH):\n",
    "  r = requests.get(url)\n",
    "  with open(path, 'wb') as f:\n",
    "    f.write(r.content)  \n",
    "  housing_tgz = tarfile.open(path)\n",
    "  housing_tgz.extractall()\n",
    "  housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro objetivo será el de predecir la variable `median_house_value` a partir del resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "NEAR OCEAN    2658\n",
       "NEAR BAY      2290\n",
       "ISLAND           5\n",
       "Name: ocean_proximity, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar tenemos variables continuas, categóricas y algunos *missing values*. Vamos a ver como podemos tratar estos aspectos con `Scikit-Learn`, aunque primero separaremos unas cuantas muestras para entrenar y el resto para evaluar nuestros modelos. Para ello vamos a utilizar la que es la funcionalidad probablemente más utilizada de la librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 16512, 4128)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2) # 20% de los datos para test, 80% para entrenamiento\n",
    "\n",
    "len(data), len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABC4AAAEYCAYAAACTNLexAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbw0lEQVR4nO3dfbBtZ10f8O/PXCWARGEIb0ngRhvEBJCXSGlRq6ISRU2sRBJUAk2bKUWhGa0m2FGmNZhOwQaq0GawElqGkEGQKFLBKFU6FLxAICQQE0xMLqRwtYqoNQj8+sdet2zO6z6555z93HM/n5kzZ59nr7X2s9fZ65s736y1TnV3AAAAAEb0ZcueAAAAAMB6FBcAAADAsBQXAAAAwLAUFwAAAMCwFBcAAADAsPYtewKbeeADH9j79+9f9jQA7pH3ve99f9rdJy57HttBHgNHO5kMMIat5vHwxcX+/ftz4MCBZU8D4B6pqj9Z9hy2izwGjnYyGWAMW81jl4oAAAAAw1JcAAAAAMNSXAAAAADDUlwAAAAAw1JcAAAAAMNSXAAAAADDUlwAAAAAw1JcAAAAAMNSXAAAAADDUlwAAAAAw9q37Amwdfsveeuyp7Cjbr/86cueAsDC9nImy2PgaLKX8ziRyRzbnHEBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxroeKiqi6uqhur6sNV9fqqOr6qHlBV76iqW6bv959b/tKqurWqbq6qp82NP7Gqbpiee0VV1U68KYC9Sh4DjEMmA+yOTYuLqjopyQuSnNndj05yXJLzklyS5LruPi3JddPPqarTp+fPSHJWkldW1XHT5l6V5KIkp01fZ23ruwHYw+QxwDhkMsDuWfRSkX1J7l1V+5LcJ8knkpyd5Krp+auSnDM9PjvJ1d19d3ffluTWJE+qqocmOaG7393dneS1c+sAsBh5DDAOmQywCzYtLrr740lemuSOJHcl+XR3vz3Jg7v7rmmZu5I8aFrlpCR3zm3i4DR20vR45fgqVXVRVR2oqgOHDh3a2jsC2KPkMcA4ZDLA7lnkUpH7Z9YQn5rkYUnuW1U/stEqa4z1BuOrB7uv7O4zu/vME088cbMpAhwT5DHAOGQywO5Z5FKR70hyW3cf6u6/S/KmJP8wySenU9syff/UtPzBJKfMrX9yZqfNHZwerxwHYDHyGGAcMhlglyxSXNyR5MlVdZ/pDsdPTfKRJNcmuWBa5oIkb5keX5vkvKq6V1WdmtkNht47nSr3map68rSdZ8+tA8Dm5DHAOGQywC7Zt9kC3f2eqnpjkvcn+VySDyS5MslXJrmmqi7MLLjPnZa/saquSXLTtPzzu/vz0+ael+Q1Se6d5G3TFwALkMcA45DJALtn0+IiSbr755L83IrhuzNrltda/rIkl60xfiDJo7c4RwAm8hhgHDIZYHcs+udQAQAAAHad4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAY1r5lT4Ctu/34Zy17Cjvs08ueAMDC9nYmy2MAYPkUFwAAwFFvbxfJiTKZY5lLRQAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGHtW/YEYKX9l7x12VPYMbdf/vRlTwFgYXs5jxOZDBxd9nImy2M244wLAAAAYFiKCwAAAGBYigsAAABgWIoLAAAAYFiKCwAAAGBYigsAAABgWIoLAAAAYFiKCwAAAGBYigsAAABgWIoLAAAAYFiKCwAAAGBYCxUXVfXVVfXGqvpoVX2kqv5BVT2gqt5RVbdM3+8/t/ylVXVrVd1cVU+bG39iVd0wPfeKqqqdeFMAe5U8BhiHTAbYHYuecfHyJP+9ux+V5BuSfCTJJUmu6+7Tklw3/ZyqOj3JeUnOSHJWkldW1XHTdl6V5KIkp01fZ23T+wA4VshjgHHIZIBdsGlxUVUnJPmWJL+SJN392e7+iyRnJ7lqWuyqJOdMj89OcnV3393dtyW5NcmTquqhSU7o7nd3dyd57dw6AGxCHgOMQyYD7J5Fzrj4miSHkvxqVX2gql5dVfdN8uDuvitJpu8PmpY/Kcmdc+sfnMZOmh6vHF+lqi6qqgNVdeDQoUNbekMAe5g8BhiHTAbYJYsUF/uSPCHJq7r78Un+OtMpb+tY65q83mB89WD3ld19ZnefeeKJJy4wRYBjgjwGGIdMBtglixQXB5Mc7O73TD+/MbOQ/uR0alum75+aW/6UufVPTvKJafzkNcYBWIw8BhiHTAbYJZsWF939v5PcWVVfNw09NclNSa5NcsE0dkGSt0yPr01yXlXdq6pOzewGQ++dTpX7TFU9ebpT8rPn1gFgE/IYYBwyGWD37FtwuR9P8rqq+ookf5zkuZmVHtdU1YVJ7khybpJ0941VdU1mwf25JM/v7s9P23lektckuXeSt01fACxOHgOMQyYD7IKFiovuvj7JmWs89dR1lr8syWVrjB9I8ugtzA+AOfIYYBwyGWB3LHKPCwAAAIClUFwAAAAAw1JcAAAAAMNSXAAAAADDUlwAAAAAw1JcAAAAAMNSXAAAAADDUlwAAAAAw1JcAAAAAMNSXAAAAADDUlwAAAAAw1JcAAAAAMNSXAAAAADD2rfsCcBKtx//rGVPYQd9etkTAAAAOKooLgCANe3tIjlRJgNHk72dyfKYjblUBAAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABjWwsVFVR1XVR+oqt+cfn5AVb2jqm6Zvt9/btlLq+rWqrq5qp42N/7Eqrpheu4VVVXb+3YA9j55DDAGeQywO7ZyxsULk3xk7udLklzX3acluW76OVV1epLzkpyR5Kwkr6yq46Z1XpXkoiSnTV9nHdHsAY5N8hhgDPIYYBcsVFxU1clJnp7k1XPDZye5anp8VZJz5sav7u67u/u2JLcmeVJVPTTJCd397u7uJK+dWweABchjgDHIY4Dds+gZF1ck+akkX5gbe3B335Uk0/cHTeMnJblzbrmD09hJ0+OV46tU1UVVdaCqDhw6dGjBKQIcE66IPAYYwRXZxTxOZDJw7Nq0uKiq703yqe5+34LbXOu6vN5gfPVg95XdfWZ3n3niiScu+LIAe5s8BhjDMvI4kcnAsWvfAss8Jcn3V9X3JDk+yQlV9d+SfLKqHtrdd02nuX1qWv5gklPm1j85ySem8ZPXGAdgMfIYYAzyGGAXbXrGRXdf2t0nd/f+zG4q9Lvd/SNJrk1ywbTYBUneMj2+Nsl5VXWvqjo1s5sMvXc6Xe4zVfXk6W7Jz55bB4BNyGOAMchjgN21yBkX67k8yTVVdWGSO5KcmyTdfWNVXZPkpiSfS/L87v78tM7zkrwmyb2TvG36AuDIyGOAMchjgB2wpeKiu9+Z5J3T4z9L8tR1lrssyWVrjB9I8uitThKALyWPAcYgjwF23qJ/VQQAAABg1ykuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGEpLgAAAIBhKS4AAACAYSkuAAAAgGHtW/YE4Fiy/5K3LnsKO+r2y5++7CkALGwvZ7I8Bo4mezmPE5m8HZxxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMa9+yJ7BT9l/y1mVPYcfcfvyyZwCwuL2cx4lMBo4e8hg4WjnjAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABjWpjfnrKpTkrw2yUOSfCHJld398qp6QJI3JNmf5PYkP9Tdfz6tc2mSC5N8PskLuvu3p/EnJnlNknsn+a0kL+zu3t63BLA3yWOAcchk2D63H/+sZU9hh3162RM46i3yV0U+l+Qnuvv9VXW/JO+rqnckeU6S67r78qq6JMklSX66qk5Pcl6SM5I8LMnvVNUju/vzSV6V5KIk/yuzUD4rydu2+03BqIQyR0gewzba25ksj3eBTAbYJZteKtLdd3X3+6fHn0nykSQnJTk7yVXTYlclOWd6fHaSq7v77u6+LcmtSZ5UVQ9NckJ3v3tqkF87tw4Am5DHAOOQyQC7Z0v3uKiq/Uken+Q9SR7c3Xcls+BO8qBpsZOS3Dm32sFp7KTp8crxtV7noqo6UFUHDh06tJUpAhwT5DHAOGQywM5auLioqq9M8mtJ/mV3/+VGi64x1huMrx7svrK7z+zuM0888cRFpwhwTJDHAOOQyQA7b6Hioqq+PLNAfl13v2ka/uR0alum75+axg8mOWVu9ZOTfGIaP3mNcQAWJI8BxiGTAXbHpsVFVVWSX0nyke7+xbmnrk1ywfT4giRvmRs/r6ruVVWnJjktyXunU+U+U1VPnrb57Ll1ANiEPAYYh0wG2D2L/FWRpyT50SQ3VNX109iLklye5JqqujDJHUnOTZLuvrGqrklyU2Z3W37+dLfkJHlevvinnt6WHbxb8t6+UzhwjJLHAOM46jJ5r+fxY059+LKnsKNuuO2OZU8BlmbT4qK735W1r71Lkqeus85lSS5bY/xAkkdvZYKsJpTh2CSPx7SXM1kew/pkMsDu2dJfFQEAAADYTYoLAAAAYFiKCwAAAGBYigsAAABgWIoLAAAAYFiKCwAAAGBYigsAAABgWIoLAAAAYFiKCwAAAGBYigsAAABgWIoLAAAAYFj7lj0BAGBMjzn14cuewo664bY7lj0FAGABiguGs5f/oewfyQAA3BP+jcyxzKUiAAAAwLAUFwAAAMCwFBcAAADAsBQXAAAAwLAUFwAAAMCwFBcAAADAsBQXAAAAwLAUFwAAAMCwFBcAAADAsBQXAAAAwLAUFwAAAMCwFBcAAADAsBQXAAAAwLAUFwAAAMCwFBcAAADAsBQXAAAAwLAUFwAAAMCwFBcAAADAsPYtewJwLHnMqQ9f9hR21A3LngDAFuzlTJbHAOwligsAAACWZi8XyYkyeTu4VAQAAAAY1p4942Kvt3YARwt5DDAGeQwcrZxxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMS3EBAAAADEtxAQAAAAxLcQEAAAAMa9eLi6o6q6purqpbq+qS3X59AGbkMcA4ZDLA+na1uKiq45L8cpLvTnJ6kvOr6vTdnAMA8hhgJDIZYGO7fcbFk5Lc2t1/3N2fTXJ1krN3eQ4AyGOAkchkgA3s2+XXOynJnXM/H0zy91cuVFUXJblo+vGvqurme/BaD0zyp/dgvb3MPlmb/bLaPdon9ZzagakM5Z7sl0fsxES2gTxeLvtkbfbLavJ4bff0s3KsZ7JjbG32y2r2ydpk8mq7kse7XVys9RvrVQPdVya58oheqOpAd595JNvYa+yTtdkvq9kna9tj+0UeL5F9sjb7ZTX7ZG17cL/sSibvwf22LeyX1eyTtdkvq+3WPtntS0UOJjll7ueTk3xil+cAgDwGGIlMBtjAbhcXf5jktKo6taq+Isl5Sa7d5TkAII8BRiKTATawq5eKdPfnqurHkvx2kuOS/JfuvnGHXu6ITm3eo+yTtdkvq9kna9sz+0UeL519sjb7ZTX7ZG17ar/sYibvqf22jeyX1eyTtdkvq+3KPqnuVZfPAQAAAAxhty8VAQAAAFiY4gIAAAAY1tKKi6rqqnrZ3M8/WVUvnh6/uKo+XlXXz3199dyyL5+e/7K5sedU1aFp2Y9W1cXrvO78cjdW1Rur6j4rlvlgVb1+enxGVf1RVd177vm3VtV527Uv1pnnj1XVrdN+euCK+f/SimXfWVWr/gRNVX1FVV1RVR+rqluq6i1VdfLc8w+pqqun52+qqt+qqkdW1f6q+r8r9v+z59Z7/DSvp614vXV/p9utqv5q+r5/et0fn3vul6rqOdPj11TVM9bZxpbfx4rP5i1V9aaqOn0H3t9Sjo9p2XOq6kPTcjdU1Tkrnv/J6bkPT8fKs6fxd1bVzXNzeuOK9f7/cTU39ppprveafn5gVd2+9T22sbnPy5dV1Sumud9QVX9YVadOz90+f6ytWP/iqvrbqvqqubFvnX5P3zc39ptV9a3T48P74/C+/KX539NIlvV5K3m8J/J42r5MlskLKXm8qWV93kom74lMLnksj7egjqJMXuYZF3cn+cfr7YQk/6G7Hzf39RfJbKcm+YEkdyb5lhXrvKG7H5fkKUl+pqpOydreMG3zjCSfTfLMw09U1ddntl++paruO90Y6U1JfmZ6/pwkX97dV2/5HW9iCtH7Tj/+zyTfkeRPjmCTL0lyvySP7O7Tkvx6kjfVJMmbk7yzu7+2u09P8qIkD57W/diK/f/aue2en+Rd0/d5m/1Od8qnkrywZnfh3op7+j4OfzZPS/KGJL9bVSdu8bU3s5Tjo6q+IclLk5zd3Y9K8v1JXlpVj52e/+dJvjPJk7r70dNrzP/t+R+em9Mz5rb7JcfVipf9fJJ/ssn+2C7PTPKwJI/t7sdktq/+YoH1zs/sju8/sGL8YKZsWMcPd/djkzw2s9/pW7Y64V0ij1eQx0dEJsvkRcjj9cnkFWTyPSaP5fGihs/kZRYXn8vsDqTrtlrr+LYkH07yqqw+mJIk3f1nSW5N8tCNNlRV+5LcN8mfzw0/K8l/TfL2zD6QSfJvkpxbVY9LcnmS529xzhuqqq+vWXN4c5JHJkl3f6C7bz+Cbd4nyXOTXNzdn5+2+auZfTC+PbP9+Hfd/Z8Or9Pd13f3H2yy3UryjCTPSfJdVXX83NP39Hd6pA4luS7JBYuusF3vo7vfkNln5VlbmO8ilnV8/GSSl3T3bdOytyX5hST/anr+RUn+RXf/5fT8p7v7qgXmtdZxddgVSS6ejsed9tAkd3X3F5Kkuw92959vtEJVfW2Sr0zyr7N6n34wyaer6js32kZ3fzbJTyV5+PQfvtHI4y/OQx4fOZn8RTJ5ffJ4fTL5i/OQyUdGHn+RPN7Y8Jm87Htc/HKSH665U0vmXFxfPJ3m9+bGz0/y+sya0O+tqi9fuWJVPTzJ8Uk+tM7rPrOqrk/y8SQPSPIb889l1hC+fnqtdPffZPZh/f0kV3f3LYu/xbVV1X2r6rlV9a4kr07ykcwarg8ssPoz5/bN9UlWnQKX5O8luePwwTPnQJIzkjw6yfs2eI2vrS89zeqbp/GnJLmtuz+W5J1JvmfFehv9TnfS5Ul+oqqOW3D57Xwf70/yqEUnugXLOD7OyOrPxYEkZ1TV/ZLcb9pn63nd3Lz+/dz4quNqzh2Ztfo/usF2t8s1Sb5vmt/LqurxC6xzeJ/+QZKvq6oHrXj+5zML7A1N/zj6YHbms7Id5LE83k4yeUYmr08eb0wmy+TtIo9n5PHGhs/kpRYXU2C8NskL1nh6/jSfb0tmp4lldvD8+rTue5J819w6z6yqG5P8cZKXd/ffrvPSh08HekiSGzI1ZVX1jUkOdfefZNZOPqGq7j/N9TcyO13mlUfwlufdleTCJP+0u5/S3a/u7s8suO4b5vbN4zI7aFaqJGv9rdv1xldaeRrc4Zb5/CSHTwG8OisOsE1+pztmaj3fm8Vb3e18H7X5Ilu3pONjrc/H4bFFPjvzp8FtelzNeUlmx+GOZlJ3H0zydUkuTfKFJNdV1VM3We28zP4x9oXMTok9d8U2/yBJ5v7hspEd+axsB3ksj7eTTJbJm5HHG5PJMnm7yGN5vIijIZOXfcZFMjsF5sLMTkfbzFlJvirJDTW7Ock35UsPpjf07Jq8b07ysqp6yEYb6+7OrEk+fJ3T+UkeNW37Y0lOSPKDc6t8YfraDs/IrM1+c1X9bFU9Ypu2e9itSR4xNYDznpDkpiQ3JnniVjY4NbU/mORnp330H5N89xqvcUUW/51up5ck+els8rnegffx+Mz+b8BOWHQOyfYcHzdm9f+deEKSm6ag/+uq+potvYPNj6t0961Jrk/yQ1vc9pZ1993d/bbpPxovSXLOesvW7LrF05K8Y5r/eVn79MLLsvF1fIc/d4/Jzn1WtsMVkcfyePvIZJm8IXm8qSsik2Xy9pDH8nhTo2fy0ouL7v4/mZ2acuECi5+fWfu6v7v3Jzk1s2uvvuSOx9397syuFXrhAtv8piQfq9kNW87N7FS0w9s/O+tcA3Wkuvvt3f3M6fU/neQtVfU7VbV/m7b/10muSvKLh08Nq9mdbe+T5Henr3tV1T87vE5VfWNV/aMNNvsdST7Y3adM++gRSX4tKz7UW/ydbpvu/mhm/8H53k0W3bb3UVU/mFlj+/r1ljkSSzg+Xprk0sOfw+n7i5IcvnvzLyT55ao6YXr+hKq6aL0JbfG4uiyz0013TFU9oaoeNje3x2bjm3udn+TFh+fe3Q9LctLKf0R199uT3D/JmtfmTacj/kKSO7t7vdNzl04ey+PtJJNl8kbk8eZkskzeLvJYHm/maMjkpRcXk5clWXln2IvrS68fOz3J05K89fACU/C8K8n3ZbV/l+S5azSEyRevf/tQZk3gv82sUf54d398brnfT3J6VW14A6Mj0d1/1t0v79npbC/K7O6xqaoXVNXBJCcn+VBVvfoebP7SJH+b5I+q6pbMDo4f6Elmd3/9zpr9qacbk7w4ySemdVdev/eCzD6gb17xGr+WtU89W+t3uhsuy2yfzfvPVXVw+np3jvx9HP5s3pLkR5J8e3cf2oa5r2fXjo/uvj6zRv43quqjmf3flp+axpPZDY1+L8kfVtWHk/yPJH8zt4n56/d+J1s4rnp2d/L3b7IvjtSDMntvH87s+sXPJZn/02kfmvus/GJm7fHKz8qbp/GV1vrsvW7KmQ9n9n8Ezt6G97DT5LE83k4yeSKTV5HHi5HJMnm7yOOJPF7T8Jlcs2MTAAAAYDyjnHEBAAAAsIriAgAAABiW4gIAAAAYluICAAAAGJbiAgAAABiW4gIAAAAYluICAAAAGNb/A3rhVwx2uhfbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "ax.hist(data['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(train['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(test['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax = plt.subplot(1, 3, 2)\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42) # siempre tendremos el mismo resultado\n",
    "ax.hist(data['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(train['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(test['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax = plt.subplot(1, 3, 3)\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=69, stratify=data['ocean_proximity']) # balancear\n",
    "ax.hist(data['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(train['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(test['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tratar los *missing values* podemos usar un `Imputer`, que puede ser tan sencillo como cambiar los valores inexistentes por el valor promedio de la columna o un valor fijo hasta el uso de algoritmos más complejos que puedes encontrar en la documentación. En este caso solo tenemos una columna con *missing values* (`total_rooms`) de tipo numérico, pero si también tuviésemos *missing values* en variables categóricas deberíamos separarlas ya que querremos usar estrategias diferentes. De hecho, es buena idea separar variables numéricas de categóricas ya que las trataremos de diferente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, y_train = train.drop(['median_house_value'], axis=1), train['median_house_value'].copy()\n",
    "test_data, y_test = test.drop(['median_house_value'], axis=1), test['median_house_value'].copy()\n",
    "\n",
    "train_num = train_data.drop(['ocean_proximity'], axis=1)\n",
    "train_cat = train_data[['ocean_proximity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.5    ,   34.26   ,   29.     , 2127.     ,  434.     ,\n",
       "       1167.5    ,  409.     ,    3.54025])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") # definir imputer\n",
    "imputer.fit(train_num) # calcular mediana\n",
    "imputer.statistics_ # valores calculado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1764e+02,  3.4040e+01,  2.1000e+01, ...,  2.5560e+03,\n",
       "         4.8400e+02,  2.4716e+00],\n",
       "       [-1.1925e+02,  3.4270e+01,  4.6000e+01, ...,  3.8200e+02,\n",
       "         1.4300e+02,  3.5000e+00],\n",
       "       [-1.1833e+02,  3.3930e+01,  3.8000e+01, ...,  4.1200e+02,\n",
       "         1.1900e+02,  6.0718e+00],\n",
       "       ...,\n",
       "       [-1.1897e+02,  3.5380e+01,  4.2000e+01, ...,  1.0380e+03,\n",
       "         2.9900e+02,  9.9510e-01],\n",
       "       [-1.1934e+02,  3.4390e+01,  2.7000e+01, ...,  3.1400e+02,\n",
       "         1.0600e+02,  2.4659e+00],\n",
       "       [-1.2232e+02,  3.7570e+01,  4.2000e+01, ...,  2.3770e+03,\n",
       "         5.8800e+02,  3.2891e+00]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num = imputer.transform(train_num) # cambiar valores inexistentes por la mediana\n",
    "\n",
    "X_train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí observamos el primer patrón que se repetirá constantemente al trabajar con `Scikit-Learn`, y es el uso de las funciones `fit` y `transform`. La primera la usaremos para calcular todo lo necesario para usar una clase (ya sea un imputer o un modelo) y, en el caso de objetos para procesado de datos, usaremos el `transform` para generar un array de `Numpy` listo para entrenar modelos, llevando a cabo todo el procesado necesario. Otro procesado muy común, que ayuda a algunos modelos a aprender mejor, es el escalado de los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96771021, -0.74756456, -0.60269331, ...,  1.03927132,\n",
       "        -0.03866464, -0.73393928],\n",
       "       [ 0.16149343, -0.6394833 ,  1.37998002, ..., -0.95584437,\n",
       "        -0.93592799, -0.19795272],\n",
       "       [ 0.62218873, -0.79925559,  0.74552456, ..., -0.92831288,\n",
       "        -0.99907849,  1.14243063],\n",
       "       ...,\n",
       "       [ 0.30170504, -0.11787378,  1.06275229, ..., -0.35382234,\n",
       "        -0.52544974, -1.5034688 ],\n",
       "       [ 0.11642541, -0.58309308, -0.12685171, ..., -1.0182491 ,\n",
       "        -1.03328501, -0.73691003],\n",
       "       [-1.37582676,  0.91124771,  1.06275229, ...,  0.87500006,\n",
       "         0.23498753, -0.30787061]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler # también hay min-max, ...\n",
    "\n",
    "scaler = StandardScaler() # mean y std\n",
    "scaler.fit(X_train_num)\n",
    "X_train_num_scaled = scaler.transform(X_train_num)\n",
    "X_train_num_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a nuestra columna categórica, no podremos usarla para entrenar modelos (necesitamos valores numéricos). Para ello tenemos que usar un `Encoder`. Además, como puedes ver, puedes usar la función `fit_transform` para llevar a cabo ambas acciones a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "X_train_cat = cat_encoder.fit_transform(train_cat)\n",
    "X_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien podemos llevar a cabo todas las transformaciones que hemos visto una a una, es mucho más práctico (y reusable) definir `Pipelines`. De esta manera podremos ir desde los datos leído hasta los datos preparados de manera muy sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "num_attribs = list(train_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "\t(\"num\", num_pipeline, num_attribs),\n",
    "\t(\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96771021, -0.74756456, -0.60269331, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.16149343, -0.6394833 ,  1.37998002, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.62218873, -0.79925559,  0.74552456, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.30170504, -0.11787378,  1.06275229, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.11642541, -0.58309308, -0.12685171, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.37582676,  0.91124771,  1.06275229, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = full_pipeline.fit_transform(train_data)\n",
    "\n",
    "X_train # contiene las variables numéricas y categóricas, sin missing values y todo escalado y codificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07386178,  0.54941047, -0.44407944, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.61718117, -0.73816619,  1.85582162, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.5671056 , -0.66297923,  0.58691069, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.70230965, -0.74756456,  1.37998002, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.09790671, -0.73816619, -0.91992104, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.2055698 ,  0.7890689 ,  0.42829682, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = full_pipeline.transform(test_data) # ojo ! aquí no hacemos fit :) sólo transform\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de `Pipelines` es muy potente, ya que puedes incluir tus modelos también y exportarlos en archivos de manera que los puedas compartir o usar en diferentes entornos (por ejemplo, para preparar los datos en producción de la misma manera que en entrenamiento)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enternando modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos los datos preparados, ya estamos listos para entrenar modelos. `Scikit-learn` trae muchísimos modelos implementados y cada uno necesitará unos parámetros diferentes. En esta serie veremos muchos de estos algoritmos, pero todos ellos implementan una interfaz similar basados, de nuevo, en la función `fit` para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez el modelo ha sido entrenado, podemos sacar predicciones con la función `predict` (recuerda pasarle los datos preparados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108292.22741445, 379888.92139725, 213135.75783887, ...,\n",
       "       215265.23261004, 122562.39714544, 318906.32084628])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lin_reg.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-Learn` también implementa multitud de `métricas` que podemos usar para evaluar nuestros modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71008.96666632878"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "preds = lin_reg.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test, preds)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar otro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66658.8766081703"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tree_reg.predict(X_test)\n",
    "tree_mse = mean_squared_error(y_test, predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que da un poco mejor 🤗 En futuros posts veremos más modelos y cómo mejorarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de hyperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de entrenar modelos de `Machine Learning` podemos usar multitud de `hyperparámteros`, el conjunto de todos aquellos parámetros que pueden afectar al entrenamiento del modelo y a su desempeño final. La forma más utilizada de optimización de hyperparámetros probar muchos y quedarse con los mejores 😝 siguiendo diferentes estrategias. Por ejemplo, podemos probar diferentes valores de un conjunto determinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "\t# 12 (3×4) combinaciones\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "\t# 6 (2×3) combinaciones\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# entrenar con 5 folds un total de (12+6)*5=90 entrenamientos\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 30}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=6, n_estimators=30, random_state=42)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63339.55618309705 {'max_features': 2, 'n_estimators': 3}\n",
      "55291.09598702181 {'max_features': 2, 'n_estimators': 10}\n",
      "52587.09831900864 {'max_features': 2, 'n_estimators': 30}\n",
      "59951.99892011206 {'max_features': 4, 'n_estimators': 3}\n",
      "52764.16418304784 {'max_features': 4, 'n_estimators': 10}\n",
      "50280.79794899106 {'max_features': 4, 'n_estimators': 30}\n",
      "58646.287306317055 {'max_features': 6, 'n_estimators': 3}\n",
      "51933.65975704695 {'max_features': 6, 'n_estimators': 10}\n",
      "49723.11534451858 {'max_features': 6, 'n_estimators': 30}\n",
      "58639.440267951104 {'max_features': 8, 'n_estimators': 3}\n",
      "51947.43577366441 {'max_features': 8, 'n_estimators': 10}\n",
      "49959.65853502058 {'max_features': 8, 'n_estimators': 30}\n",
      "62660.85578333314 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "53682.43657349913 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "60016.802813202616 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "53224.05340560518 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "58561.732410130135 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51914.87547403448 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49214.84552444808"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "preds = best_model.predict(X_test)\n",
    "final_mse = mean_squared_error(y_test, preds)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post hemos visto las herramientas más usadas en el ecosistema `Python` para `Machine Learning`. Herramientas como `Python`, `Numpy`, `Pandas` o `Matplotlib` ya las hemos visto en posts anteriores. Aquí, nos hemos centrado en la librería `Scikit-Learn`, probablemente la más usada a día de hoy para entrenar modelos de ML en `Python`. Hemos visto como podemos usar la funcionalidad de la librería para preparar nuestros datos, creando `Pipelines` reutilizables, entrenar modelos y optimizar sus hyperparámetros para obtener los mejores modelos posibles. En los siguientes posts entraremos en detalle en diferentes modelos que encontramos en la librería con ejemplos de aplicación."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74dbfc52f168b3071122cf9c0781887d6121c12f9c1b29bca56ce221bccb2a07"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
