{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/082_sensio_copilot/082_sensio_copilot.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensio CoPilot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post vamos a entrenar una red neuronal para generación de código similar al funcionamiento de [github Copilot](https://copilot.github.com/). Llevo usando Copilot unos meses y la verdad que puedo decir que es una herramienta increíble, que ha aumentado considerablemente mi productividad como programador. Hace unos días leí [este](https://twitter.com/lvwerra/status/1467933794699259908?s=21) hilo en Twitter y creí que sería interesante intentar replicar un sistema como Copilot desde cero. Así que sin más dilación, ¡vamos a ello!\n",
    "\n",
    "Github Copilot utiliza el modelo conocido como [Codex](https://arxiv.org/abs/2107.03374), desarrollado por OpenAI. Este modelo está basado en la arquitectura GPT (de lo que hablaremos más adelante) y *tuneado* con código público extraído de Github. Esto significa que el modelo fue pre-entrenado de manera no supervisada con mucho texto y luego se hizo *fine tuning* con el código extraído de Github para la tarea de generación de texto (nuevo código autocompletado). En contraste, nosotros entrenaremos un modelo desde cero para la tarea de generación de texto con un dataset preparado para ello a modo de demostración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset usado por OpenAI para entrenar Codex fue extraído de 54 millones de reposiotrios públicos de Github, conteniendo 179 GB de archivos Python de menos de 1 MB. Tras varias etapas de procesado, el dataset final ocupó 159 GB. Como no tenemos acceso a este dataset, usaremos [CodeParrot](https://huggingface.co/datasets/lvwerra/codeparrot-clean), un dataset elaborado por [HuggingFace](https://huggingface.co/) para la tarea de generación de código.\n",
    "\n",
    "> Recuerda que OpenAI al final tiene que ganar dinero de alguna manera, y ésta es cobrando por el uso de sus modelos a través de la API. Siendo el modelo público, su única ventaja competitiva reside en los datos usados durante el entrenamiento. Esto es una tendencia clara en el mundo del Software 2.0, dónde el valor real está en los datos y no en el código (aunque como diría Andrej Karpathy en el Software 2.0 los datos SON el código y el modelo no es más que el binario resultante de la compilación del mismo, lo que llamamos el proceso de entrenamiento).\n",
    "\n",
    "El dataset ocupa unos 50 GB, aproximadamente una tercera parte del dataset usado originalmente por OpenAI. ¡Nada mal! Puedes descargarlo utilizando los siguientes comandos:\n",
    "\n",
    "```\n",
    "git clone https://huggingface.co/datasets/lvwerra/codeparrot-clean-train\n",
    "git clone https://huggingface.co/datasets/lvwerra/codeparrot-clean-valid\n",
    "```\n",
    "\n",
    "> Para poder descargarlos necesitarás instalar [Git LFS](https://git-lfs.github.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52,\n",
       " ['codeparrot-clean-train/file-000000000007.json.gz',\n",
       "  'codeparrot-clean-train/file-000000000053.json.gz',\n",
       "  'codeparrot-clean-train/file-000000000026.json.gz'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "path = Path('data/codeparrot-clean-train')\n",
    "\n",
    "files = glob(str(path) + '/*.json.gz')\n",
    "len(files), files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>path</th>\n",
       "      <th>copies</th>\n",
       "      <th>size</th>\n",
       "      <th>content</th>\n",
       "      <th>license</th>\n",
       "      <th>hash</th>\n",
       "      <th>line_mean</th>\n",
       "      <th>line_max</th>\n",
       "      <th>alpha_frac</th>\n",
       "      <th>autogenerated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jalavik/inspire-next</td>\n",
       "      <td>setup.py</td>\n",
       "      <td>1</td>\n",
       "      <td>4558</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n#\\n# This file is par...</td>\n",
       "      <td>gpl-2.0</td>\n",
       "      <td>-4849180608980663294</td>\n",
       "      <td>27.848101</td>\n",
       "      <td>77</td>\n",
       "      <td>0.615840</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dlzhangxg/cloud-ml-sdk</td>\n",
       "      <td>cloud_ml_samples/keras/mnist/trainer/task.py</td>\n",
       "      <td>1</td>\n",
       "      <td>2967</td>\n",
       "      <td># Copyright 2017 Xiaomi, Inc.\\n#\\n# Licensed u...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>-1822461891537938192</td>\n",
       "      <td>30.231579</td>\n",
       "      <td>74</td>\n",
       "      <td>0.649815</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openstack/heat</td>\n",
       "      <td>heat/engine/support.py</td>\n",
       "      <td>1</td>\n",
       "      <td>2683</td>\n",
       "      <td>#\\n#    Licensed under the Apache License, Ver...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>-1815098437948811103</td>\n",
       "      <td>36.788732</td>\n",
       "      <td>78</td>\n",
       "      <td>0.622438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imapp-pl/golem</td>\n",
       "      <td>tests/golem/network/test_golem_protocol.py</td>\n",
       "      <td>1</td>\n",
       "      <td>1444</td>\n",
       "      <td>import unittest\\nfrom devp2p.service import Wi...</td>\n",
       "      <td>gpl-3.0</td>\n",
       "      <td>-5671972220290336808</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>77</td>\n",
       "      <td>0.654432</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>willimoa/pydal</td>\n",
       "      <td>pydal/dialects/mongo.py</td>\n",
       "      <td>1</td>\n",
       "      <td>22083</td>\n",
       "      <td>import re\\nfrom .._compat import PY2, basestri...</td>\n",
       "      <td>bsd-3-clause</td>\n",
       "      <td>7148857323817256703</td>\n",
       "      <td>34.389423</td>\n",
       "      <td>93</td>\n",
       "      <td>0.518951</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>georgestarcher/TA-SyncKVStore</td>\n",
       "      <td>bin/ta_synckvstore/cloudconnectlib/core/ext.py</td>\n",
       "      <td>1</td>\n",
       "      <td>10300</td>\n",
       "      <td>import calendar\\nimport json\\nimport re\\nimpor...</td>\n",
       "      <td>mit</td>\n",
       "      <td>-2116068727318744484</td>\n",
       "      <td>29.654762</td>\n",
       "      <td>80</td>\n",
       "      <td>0.593495</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>nabucosound/django-propaganda</td>\n",
       "      <td>propaganda/migrations/0001_initial.py</td>\n",
       "      <td>1</td>\n",
       "      <td>2828</td>\n",
       "      <td># -*- coding: utf-8 -*-\\nfrom __future__ impor...</td>\n",
       "      <td>bsd-3-clause</td>\n",
       "      <td>2285667758777388556</td>\n",
       "      <td>38.830986</td>\n",
       "      <td>114</td>\n",
       "      <td>0.541372</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>znuxor/aoc2016</td>\n",
       "      <td>4.py</td>\n",
       "      <td>1</td>\n",
       "      <td>41871</td>\n",
       "      <td>#!/usr/bin/python3\\nimport operator\\n\\n# room ...</td>\n",
       "      <td>bsd-3-clause</td>\n",
       "      <td>-2104829268388077325</td>\n",
       "      <td>40.662687</td>\n",
       "      <td>118</td>\n",
       "      <td>0.834659</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>sharadagarwal/autorest</td>\n",
       "      <td>AutoRest/Generators/Python/Python.Tests/Expect...</td>\n",
       "      <td>1</td>\n",
       "      <td>5365</td>\n",
       "      <td># coding=utf-8\\n# ----------------------------...</td>\n",
       "      <td>mit</td>\n",
       "      <td>-2646046330546511516</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>110</td>\n",
       "      <td>0.630009</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>DeathSurvivorDE/dhbw_schreitbagger</td>\n",
       "      <td>Schreitbagger/Bagger_GUI_v0-0-0-3_st.py</td>\n",
       "      <td>1</td>\n",
       "      <td>8009</td>\n",
       "      <td>\\n'''\\nBagger_GUI v0.0.0.1\\n\\nGrafische Benutz...</td>\n",
       "      <td>gpl-3.0</td>\n",
       "      <td>54990144954214641</td>\n",
       "      <td>54.020690</td>\n",
       "      <td>212</td>\n",
       "      <td>0.507145</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                repo_name  \\\n",
       "0                    jalavik/inspire-next   \n",
       "1                  dlzhangxg/cloud-ml-sdk   \n",
       "2                          openstack/heat   \n",
       "3                          imapp-pl/golem   \n",
       "4                          willimoa/pydal   \n",
       "...                                   ...   \n",
       "99995       georgestarcher/TA-SyncKVStore   \n",
       "99996       nabucosound/django-propaganda   \n",
       "99997                      znuxor/aoc2016   \n",
       "99998              sharadagarwal/autorest   \n",
       "99999  DeathSurvivorDE/dhbw_schreitbagger   \n",
       "\n",
       "                                                    path  copies   size  \\\n",
       "0                                               setup.py       1   4558   \n",
       "1           cloud_ml_samples/keras/mnist/trainer/task.py       1   2967   \n",
       "2                                 heat/engine/support.py       1   2683   \n",
       "3             tests/golem/network/test_golem_protocol.py       1   1444   \n",
       "4                                pydal/dialects/mongo.py       1  22083   \n",
       "...                                                  ...     ...    ...   \n",
       "99995     bin/ta_synckvstore/cloudconnectlib/core/ext.py       1  10300   \n",
       "99996              propaganda/migrations/0001_initial.py       1   2828   \n",
       "99997                                               4.py       1  41871   \n",
       "99998  AutoRest/Generators/Python/Python.Tests/Expect...       1   5365   \n",
       "99999            Schreitbagger/Bagger_GUI_v0-0-0-3_st.py       1   8009   \n",
       "\n",
       "                                                 content       license  \\\n",
       "0      # -*- coding: utf-8 -*-\\n#\\n# This file is par...       gpl-2.0   \n",
       "1      # Copyright 2017 Xiaomi, Inc.\\n#\\n# Licensed u...    apache-2.0   \n",
       "2      #\\n#    Licensed under the Apache License, Ver...    apache-2.0   \n",
       "3      import unittest\\nfrom devp2p.service import Wi...       gpl-3.0   \n",
       "4      import re\\nfrom .._compat import PY2, basestri...  bsd-3-clause   \n",
       "...                                                  ...           ...   \n",
       "99995  import calendar\\nimport json\\nimport re\\nimpor...           mit   \n",
       "99996  # -*- coding: utf-8 -*-\\nfrom __future__ impor...  bsd-3-clause   \n",
       "99997  #!/usr/bin/python3\\nimport operator\\n\\n# room ...  bsd-3-clause   \n",
       "99998  # coding=utf-8\\n# ----------------------------...           mit   \n",
       "99999  \\n'''\\nBagger_GUI v0.0.0.1\\n\\nGrafische Benutz...       gpl-3.0   \n",
       "\n",
       "                      hash  line_mean  line_max  alpha_frac  autogenerated  \n",
       "0     -4849180608980663294  27.848101        77    0.615840          False  \n",
       "1     -1822461891537938192  30.231579        74    0.649815          False  \n",
       "2     -1815098437948811103  36.788732        78    0.622438          False  \n",
       "3     -5671972220290336808  37.000000        77    0.654432          False  \n",
       "4      7148857323817256703  34.389423        93    0.518951          False  \n",
       "...                    ...        ...       ...         ...            ...  \n",
       "99995 -2116068727318744484  29.654762        80    0.593495          False  \n",
       "99996  2285667758777388556  38.830986       114    0.541372          False  \n",
       "99997 -2104829268388077325  40.662687       118    0.834659          False  \n",
       "99998 -2646046330546511516  35.250000       110    0.630009          False  \n",
       "99999    54990144954214641  54.020690       212    0.507145          False  \n",
       "\n",
       "[100000 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "sample = pd.read_json(files[2], lines=True)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#!/usr/bin/env python\\n\\n# Copyright (C) 2014 Aldebaran Robotics\\n#\\n# Licensed under the Apache License, Version 2.0 (the \"License\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n#\\n# Unless required by applicable law or agreed to in writing, software\\n# distributed under the License is distributed on an \"AS IS\" BASIS,\\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n# See the License for the specific language governing permissions and\\n# limitations under the License.\\n#\\n#import ROS dependencies\\nimport rospy\\n\\n#import NAO dependencies\\nfrom naoqi_driver.naoqi_node import NaoqiNode\\nfrom geometry_msgs.msg import PoseStamped\\nfrom geometry_msgs.msg import Pose\\nimport almath\\nimport tf\\nfrom tf.transformations import euler_from_quaternion\\n\\nclass MoveToListener(NaoqiNode):\\n\\n    def __init__(self):\\n        NaoqiNode.__init__(self, \\'naoqi_moveto_listener\\')\\n        self.connectNaoQi()\\n        self.listener = tf.TransformListener()\\n\\n        self.subscriber = rospy.Subscriber(\"/move_base_simple/goal\", PoseStamped, self.callback)\\n\\n    # (re-) connect to NaoQI:\\n    def connectNaoQi(self):\\n        rospy.loginfo(\"Connecting to NaoQi at %s:%d\", self.pip, self.pport)\\n\\n        self.motionProxy = self.get_proxy(\"ALMotion\")\\n        if self.motionProxy is None:\\n            exit(1)\\n\\n    def callback(self, poseStamped):\\n        # reset timestamp because of bug: https://github.com/ros/geometry/issues/82\\n        poseStamped.header.stamp = rospy.Time(0)\\n        try:\\n            robotToTarget1 = self.listener.transformPose(\"/base_footprint\", poseStamped)\\n        except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException) as e:\\n            rospy.logerr(\"Error while transforming pose: %s\", str(e))\\n            return\\n        quat = robotToTarget1.pose.orientation\\n        (roll,pitch,yaw) = euler_from_quaternion((quat.x, quat.y, quat.z, quat.w))\\n        self.motionProxy.moveTo(robotToTarget1.pose.position.x, robotToTarget1.pose.position.y, yaw)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.content[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo usado por OpenAI, Codex, está basado en la arquitectura [GPT](https://paperswithcode.com/method/gpt) y contiene 12 billones de parámetros. Esto está un poco fuera de nuestra alcance (de momento 😝) así que usaremos la implementación de Karpathy, [minGPT](https://github.com/karpathy/minGPT), que nos permite entrenar pequeños transformers basados en la arquitectura GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit one sample con función def sum(a, b): return a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit one batch del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train Codex using the same learning rate as the corresponding GPT model, with a 175 step linear warmup and\n",
    "cosine learning rate decay. We train for a total of 100 billion\n",
    "tokens, using the Adam optimizer with β1 = 0.9, β2 = 0.95, eps = 10−8, and a weight decay coefficient of 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejoras: usar tokenizer pre-entrenado (gpt3), usar modelo más grande, ...\n",
    "Next: meter en una api (por ejemplo heroku), hacer vscode extension, ..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74dbfc52f168b3071122cf9c0781887d6121c12f9c1b29bca56ce221bccb2a07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
