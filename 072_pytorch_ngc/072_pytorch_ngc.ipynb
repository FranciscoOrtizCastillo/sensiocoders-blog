{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff2464c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/072_pytorch_ngc/072_pytorch_ngc.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e829199e",
   "metadata": {},
   "source": [
    "# Pytorch NGC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f0058",
   "metadata": {},
   "source": [
    "En los posts anteriores hemos visto muchos trucos para optimizar nuestro código en Pytorch, sin embargo no nos hemos preocupado por la instalación del mismo. En este post vamos a aprender a usar una versión de `Pytorch` optimizada que en alguna ocasión nos dará un pequeño extra de performance. Para ello vamos a usar `Docker`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785f4f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T13:43:42.114525Z",
     "start_time": "2021-06-29T13:43:42.108116Z"
    }
   },
   "source": [
    "- Imágen con `Pytorch`: https://ngc.nvidia.com/catalog/containers/nvidia:pytorch\n",
    "- Instala `Docker`: https://docs.docker.com/engine/install/ubuntu/\n",
    "- Instala `nvidia-docker`: https://github.com/NVIDIA/nvidia-docker\n",
    "- Opcionalmente, instala `docker-compose`: https://docs.docker.com/compose/install/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d7020b",
   "metadata": {},
   "source": [
    "## Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc59d86",
   "metadata": {},
   "source": [
    "> No es el objetivo de este post explicar en detalle qué es `Docker` o para qué sirve. Existen muchos recursos en internet que puedes usar para aprender más sobre esta tecnología."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89dd03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3740d2ea",
   "metadata": {},
   "source": [
    "## Notebooks en Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb3823",
   "metadata": {},
   "source": [
    "docker run --gpus all --ipc=host --rm -v local_dir:container_dir nvcr.io/nvidia/pytorch:xx.xx-py3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167539a",
   "metadata": {},
   "source": [
    "docker run --gpus all --ipc=host --rm  nvcr.io/nvidia/pytorch:21.06-py3 echo \"hola\"\n",
    "\n",
    "docker run --gpus all --ipc=host --rm  nvcr.io/nvidia/pytorch:21.06-py3 pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4a630",
   "metadata": {},
   "source": [
    "docker run --gpus all --ipc=host --rm -v $PWD/072_pytorch_ngc:/workspace  -p 8888:8888 nvcr.io/nvidia/pytorch:21.06-py3 jupyter notebook --allow-root --ip=0.0.0.0 --no-browser --NotebookApp.token=abc123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f25b53",
   "metadata": {},
   "source": [
    "```\n",
    "docker run --gpus all --ipc=host --rm -v $PWD/072_pytorch_ngc:/workspace -v $PWD/072_pytorch_ngc/data:/workspace/data  -p 8888:8888 nvcr.io/nvidia/pytorch:21.06-py3 jupyter notebook --allow-root --ip=0.0.0.0 --no-browser --NotebookApp.token=abc123\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e926c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0a0+c3d40fd'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540bac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20817bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images and labels ...\n",
      "Number of images: 27000\n",
      "Generating train / val splits ...\n",
      "Training samples:  21600\n",
      "Validation samples:  5400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def setup(path='./data', test_size=0.2, random_state=42):\n",
    "\n",
    "    classes = sorted(os.listdir(path))\n",
    "\n",
    "    print(\"Generating images and labels ...\")\n",
    "    images, encoded = [], []\n",
    "    for ix, label in enumerate(classes):\n",
    "        _images = os.listdir(f'{path}/{label}')\n",
    "        images += [f'{path}/{label}/{img}' for img in _images]\n",
    "        encoded += [ix]*len(_images)\n",
    "    print(f'Number of images: {len(images)}')\n",
    "\n",
    "     # train / val split\n",
    "    print(\"Generating train / val splits ...\")\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "        images,\n",
    "        encoded,\n",
    "        stratify=encoded,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(\"Training samples: \", len(train_labels))\n",
    "    print(\"Validation samples: \", len(val_labels))\n",
    "    \n",
    "    return classes, train_images, train_labels, val_images, val_labels\n",
    "\n",
    "classes, train_images, train_labels, val_images, val_labels = setup('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94311af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import io \n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        img = io.imread(self.images[ix])[...,(3,2,1)]\n",
    "        img = torch.tensor(img / 4000, dtype=torch.float).clip(0,1).permute(2,0,1)  \n",
    "        label = torch.tensor(self.labels[ix], dtype=torch.long)        \n",
    "        return img, label\n",
    "    \n",
    "ds = {\n",
    "    'train': Dataset(train_images, train_labels),\n",
    "    'val': Dataset(val_images, val_labels)\n",
    "}\n",
    "\n",
    "batch_size = 1024\n",
    "dl = {\n",
    "    'train': torch.utils.data.DataLoader(ds['train'], batch_size=batch_size, shuffle=True, num_workers=20, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(ds['val'], batch_size=batch_size, shuffle=False, num_workers=20, pin_memory=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da9a3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_outputs=10, use_amp=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('tf_efficientnet_b5', pretrained=True, num_classes=n_outputs)\n",
    "        self.use_amp = use_amp\n",
    "\n",
    "    def forward(self, x, log=False):\n",
    "        if log:\n",
    "            print(x.shape)\n",
    "        with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "            return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b3d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def step(model, batch, device):\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_hat = model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    acc = (torch.argmax(y_hat, axis=1) == y).sum().item() / y.size(0)\n",
    "    return loss, acc\n",
    "\n",
    "def train_amp(model, dl, optimizer, epochs=10, device=\"cpu\", use_amp = True, prof=None, end=0):\n",
    "    model.to(device)\n",
    "    hist = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    for e in range(1, epochs+1):\n",
    "        # train\n",
    "        model.train()\n",
    "        l, a = [], []\n",
    "        bar = tqdm(dl['train'])\n",
    "        stop=False\n",
    "        for batch_idx, batch in enumerate(bar):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # AMP\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                loss, acc = step(model, batch, device)\n",
    "            scaler.scale(loss).backward()\n",
    "            # gradient clipping \n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            l.append(loss.item())\n",
    "            a.append(acc)\n",
    "            bar.set_description(f\"training... loss {np.mean(l):.4f} acc {np.mean(a):.4f}\")\n",
    "            # profiling\n",
    "            if prof:\n",
    "                if batch_idx >= end:\n",
    "                    stop = True\n",
    "                    break\n",
    "                prof.step()  \n",
    "        hist['loss'].append(np.mean(l))\n",
    "        hist['acc'].append(np.mean(a))\n",
    "        if stop:\n",
    "            break\n",
    "        # eval\n",
    "        model.eval()\n",
    "        l, a = [], []\n",
    "        bar = tqdm(dl['val'])\n",
    "        with torch.no_grad():\n",
    "            for batch in bar:\n",
    "                loss, acc = step(model, batch, device)\n",
    "                l.append(loss.item())\n",
    "                a.append(acc)\n",
    "                bar.set_description(f\"evluating... loss {np.mean(l):.4f} acc {np.mean(a):.4f}\")\n",
    "        hist['val_loss'].append(np.mean(l))\n",
    "        hist['val_acc'].append(np.mean(a))\n",
    "        # log\n",
    "        log = f'Epoch {e}/{epochs}'\n",
    "        for k, v in hist.items():\n",
    "            log += f' {k} {v[-1]:.4f}'\n",
    "        print(log)\n",
    "        \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3a0699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b5_ra-9a3e5369.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b5_ra-9a3e5369.pth\n",
      "training... loss 1.7557 acc 0.6718: 100%|██████████| 22/22 [00:14<00:00,  1.49it/s]\n",
      "evluating... loss 24.6224 acc 0.4783: 100%|██████████| 6/6 [00:02<00:00,  2.52it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss 1.7557 acc 0.6718 val_loss 24.6224 val_acc 0.4783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.2032 acc 0.9370: 100%|██████████| 22/22 [00:11<00:00,  1.88it/s]\n",
      "evluating... loss 0.4083 acc 0.8991: 100%|██████████| 6/6 [00:02<00:00,  2.62it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss 0.2032 acc 0.9370 val_loss 0.4083 val_acc 0.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.0604 acc 0.9807: 100%|██████████| 22/22 [00:11<00:00,  1.94it/s]\n",
      "evluating... loss 0.1867 acc 0.9491: 100%|██████████| 6/6 [00:02<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss 0.0604 acc 0.9807 val_loss 0.1867 val_acc 0.9491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "hist = train_amp(model, dl, optimizer, epochs=3, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8790c736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8b158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])torch.Size([16, 3, 32, 32])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "\n",
    "# cada gpu recibe la mitad del batch !\n",
    "output = model(torch.randn(32, 3, 32, 32).cuda(), log=True)\n",
    "\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5445ea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 2.1215 acc 0.6086: 100%|██████████| 11/11 [00:08<00:00,  1.29it/s]\n",
      "evluating... loss 19.9792 acc 0.1761: 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss 2.1215 acc 0.6086 val_loss 19.9792 val_acc 0.1761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.2685 acc 0.9155: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s]\n",
      "evluating... loss 7.6862 acc 0.3792: 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss 0.2685 acc 0.9155 val_loss 7.6862 val_acc 0.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.0880 acc 0.9704: 100%|██████████| 11/11 [00:07<00:00,  1.40it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "dl = {\n",
    "    'train': torch.utils.data.DataLoader(ds['train'], batch_size=batch_size, shuffle=True, num_workers=20, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(ds['val'], batch_size=batch_size, shuffle=False, num_workers=20, pin_memory=True)\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "hist = train_amp(model, dl, optimizer, epochs=3, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42096cf",
   "metadata": {},
   "source": [
    "docker-compose up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ab883",
   "metadata": {},
   "source": [
    "docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f11ba",
   "metadata": {},
   "source": [
    "docker-compose down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e6e2e",
   "metadata": {},
   "source": [
    "## Scripts en Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac37a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd0807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e1ca6cb",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1af6d",
   "metadata": {},
   "source": [
    "Usar una versión de `Pytorch` optimizada, como las que nos provee `NVIDIA` a través de su servicio `NGC` puede darnos un extra de performance en ciertas ocasiones ya que el código ha sido tuneado por expertos en vez de recurrir a una versión instalable genérica que puede hacer algún compromiso para evitar posibles conflictos con hardware o sistemas operativos. En este post hemos visto como podemos ejectur nuestros notebooks y scripts de `Python` con `Docker` y `docker-compose`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
