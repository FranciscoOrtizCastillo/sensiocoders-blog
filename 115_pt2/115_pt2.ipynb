{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/115_pt2/115_pt2.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 2.0 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pytorch 2.0](https://pytorch.org/) ya está aquí 🎉🎉🎉 Tras varios meses en fase beta, la segunda versión de nuestro framework favorito de deep learning ya está disponible. Si ya sabes trabajar con Pytorch, este post te servirá para refrescar algunos conocimientos básicos a la vez que aprenderás sobre las novedades de Pytorch 2.0. Por otro lado, si no sabes nada de Pytorch, este post te servirá como introducción para aprender a usarlo desde cero.\n",
    "\n",
    "> En mi canal de Yotube tengo una [lista](https://www.youtube.com/watch?v=WL50sQVdQFg&list=PLkgbkukKg_Nrk7OtpwZEdVa10LijfpyZ1) de reproducción con todos los vídeos que he grabado sobre Pytorch. Te recomiendo que le eches un vistazo si quieres aprender más sobre este framework."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es Pytorch?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pytorch` es un framework de `redes neuronales`, un conjunto de librerías y herramientas que nos hacen la vida más fácil a la hora de diseñar, entrenar y poner en producción nuestros modelos de `Deep Learning`. Una forma sencilla de entender qué es `Pytorch` es la siguiente:\n",
    "\n",
    "$$ Pytorch = Numpy + Autograd + GPU $$\n",
    "\n",
    "Quizás la característica más relevante de Pytorch es su facilidad de uso. Esto es debido a que sigue una interfaz muy similar a la de `NumPy`, por lo que si estás familiarizado con esta librería no debería costarte mucho usar `Pytorch` 😁.\n",
    "\n",
    "> Si no conces `Numpy` te recomiendo que le eches un vistazo a este [post](https://www.sensiocoders.com/blog/007_numpy).\n",
    "\n",
    "Sin embargo, la funcionalidad más importante que `Pytorch` ofrece es la conocidad como `autograd`, la cual nos proporciona la posibilidad de calcular derivadas de manera automática con respecto a cualquier `tensor`. Esto le da a Pytorch un gran potencial para diseñar redes neuronales complejas y entrenarlas utilizando algoritmos de descenso por gradiente sin tener que calcular todas estas derivadas manualmente. Para poder llevar a cabo estas operaciones, Pytorch va construyendo de manera dinámica un `grafo computacional`. Cada vez que aplicamos una operación sobre uno o varios tensores, éstos se añaden al grafo computacional junto a la operación en concreto. De esta manera, si queremos calcular la derivada de cualquier valor con respecto a cualquier tensor, simplemente tenemos que aplicar el algoritmo de `backpropagation` (que no es más que la regla de la cadena de la derivada) en el grafo.\n",
    "\n",
    "Para que todo esto funcione de manera eficiente, Pytorch nos d ala posibilidad de ejecutar nuestro códigp en `GPU`s. Esto es posible gracias a que Pytorch está construido sobre `CUDA`, una librería de `C++` que nos permite programar en `GPU`. Por lo tanto, si tienes una `GPU` disponible, Pytorch la utilizará sin prácticamente ningún cambio en tu código para acelerar los cálculos. Si no tienes una GPU, puedes usar servicios como [Google Colab](https://colab.research.google.com/) o [Kaggle](https://www.kaggle.com/) para ejecutar tu código en la nube."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso para empezar a trabajar con `Pytorch` es instalarlo. Para ello, puedes seguir las instrucciones que aparecen en la [página oficial](https://pytorch.org/). En mi caso, voy a instalarlo usando `conda` en un ordenador con Linux y con soporte `GPU`:\n",
    "\n",
    "```bash\n",
    "conda install pytorch torchvision pytorch-cuda=11.7 -c pytorch -c nvidia\n",
    "```\n",
    "\n",
    "> Si no sabes como instalar `Python` o `Conda` en tu sistema, puedes aprender a hacerlo en este [post](https://www.sensiocoders.com/blog/001_python). También te recomiendo crear un entorno virtual para tu nueva instalación, así evitarás conflictos con otros proyectos que tengas en marcha. \n",
    "\n",
    "En el momento de escribir este post el comando anterior instalará la versión de `Pytorch` 2.0, en el momento en el que tu lo hagas instalará la versión más reciente hasta la fecha. Para instalar versiones diferentes vista https://pytorch.org/get-started/previous-versions/.\n",
    "\n",
    "Una vez instalado ya podrás empezar a trabajar con `Pytorch` 🎉🎉🎉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0.dev20230213+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber si la `GPU` está disponible, puedes ejecutar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente comando te dará información sobre tu sistema (si no funciona deberás primero instalar los drivers de `NVIDIA`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 17 10:09:05 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.05    Driver Version: 525.85.05    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:17:00.0 Off |                  N/A |\n",
      "|  0%   55C    P0   106W / 350W |     29MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "|  0%   56C    P8    29W / 350W |      8MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1378      G   /usr/lib/xorg/Xorg                 16MiB |\n",
      "|    0   N/A  N/A      1622      G   /usr/bin/gnome-shell                8MiB |\n",
      "|    1   N/A  N/A      1378      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeros pasos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como comentabamos antes, `Pytorch` es muy similar a `Numpy`. Si bien el objeto principal en `Numpy` es el `array`, en `Pytorch` es el `tensor`. Un `tensor` es una matriz multidimensional con un tipo de datos concreto. Por ejemplo, podemos crear un `tensor` de 2x2 con ceros de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2, 2)\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes crear tensores con valores aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2063,  0.7455, -0.0131])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E incluso a partir de una lista de `Python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3],[4, 5, 6]])\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U otro array de `Numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [4, 5],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 2],[4, 5],[5, 6]])\n",
    "x = torch.from_numpy(a)\n",
    "x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y como puedes esperar, prácticamente todos los conceptos que ya conocemos para trabajar con `NumPy` pueden aplicarse en `Pytorch`. Esto incluye operaciones aritméticas, indexado y troceado, iteración, vectorización y broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.6784,  1.7195, -0.5614],\n",
       "         [ 1.0342, -0.5727, -0.4840],\n",
       "         [ 0.4360,  1.4932,  0.3966]]),\n",
       " tensor([[ 1.0446,  0.3586, -0.9713],\n",
       "         [-0.1943, -3.3726,  0.1241],\n",
       "         [ 0.1605, -0.0124, -1.3009]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# operaciones\n",
    "\n",
    "x = torch.randn(3, 3)\n",
    "y = torch.randn(3, 3)\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.7230,  2.0781, -1.5328],\n",
       "        [ 0.8399, -3.9453, -0.3599],\n",
       "        [ 0.5965,  1.4808, -0.9044]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6338,  1.3609,  0.4099],\n",
       "        [ 1.2285,  2.7999, -0.6082],\n",
       "        [ 0.2755,  1.5055,  1.6975]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6784,  1.7195, -0.5614])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexado\n",
    "\n",
    "# primera fila\n",
    "\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# primera fila, primera columna\n",
    "\n",
    "x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6784,  1.7195, -0.5614])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# primera columna\n",
    "\n",
    "x[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7195, -0.5614],\n",
       "        [-0.5727, -0.4840]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# troceado\n",
    "\n",
    "x[:-1, 1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una funcionalidad importante del objeto `tensor` que utilizaremos muy a menudo es cambiar su forma. Esto lo conseguimos con la función `view`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# añadimos una dimensión extra\n",
    "\n",
    "x.view(1, 3, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estiramos en una sola dimensión\n",
    "\n",
    "x.view(9).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usamos -1 para asignar todos los valores restantes a una dimensión\n",
    "\n",
    "x.view(-1).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos transformar un `tensor` en un `array` con la función `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6783874,  1.7194802, -0.5614443],\n",
       "       [ 1.0342228, -0.5727211, -0.484026 ],\n",
       "       [ 0.4360042,  1.4931623,  0.3965516]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aprender más sobre cómo funcionan estos tensores, puedes cosultar la [documentación](https://pytorch.org/docs/stable/tensors.html) y este [ejemplo](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver un ejemplo de `autograd` en acción para el cálculo de derivadas automáticas. Para ello, consideremos el siguiente grafo computacional sencillo:\n",
    "\n",
    "![](https://www.tutorialspoint.com/python_deep_learning/images/computational_graph_equation2.jpg)\n",
    "\n",
    "Tenemos tres `tensores`, $x$, $y$ y $z$, los cuales combinamos con diferente operacion para calcular $g$. ¿Cómo podemos encontrar la derivada de $g$ con respecto a cada uno de los tensores a la entrada?. Para el caso de $z$ esto es sencillo:\n",
    "\n",
    "$$ \\frac{dg}{dz} = p = x + y$$\n",
    "\n",
    "En el caso de $x$ y $y$ es un poco más complicado, ya que tenemos que aplicar la regla de la cadena de la derivada:\n",
    "\n",
    "$$ \\frac{dg}{dx} = \\frac{dg}{dp} \\frac{dp}{dx} = z $$\n",
    "$$ \\frac{dg}{dy} = \\frac{dg}{dp} \\frac{dp}{dy} = z $$\n",
    "\n",
    "Si bien en este ejemplo sencillo lo hemos podido calcular a mano, imagina tener que hacer esto en redes neuronales con miles de millones de parámetros... imposible. `Autograd` nos permite calcular estas derivadas de manera automática. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1., requires_grad=True)\n",
    "y = torch.tensor(2., requires_grad=True)\n",
    "p = x + y\n",
    "\n",
    "z = torch.tensor(3., requires_grad=True)\n",
    "g = p * z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello marcaremos los `tensores` de los cuales queremos calcular derivadas con la función `requires_grad`. Llamado a la función `backwerd` sobre el `tensor` de salida, `autograd` calculará las derivadas de manera automática y las almacenará en el atributo `grad` de cada `tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad # x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad # z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad # z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, el `grafo computacional` es una herramienta extraordinaria para diseñar `redes neuronales` de complejidad arbitraria. Con una simple función, gracias al algoritmo de `backpropagation`, podemos calcular todas las derivadas de manera sencilla (cada nodo que representa una operación solo necesita calcular su propia derivada de manera local) y optimizar el modelo con nuestro algoritmo de gradiente preferido.\n",
    "\n",
    "Añadiendo `autograd` encima de `NumPy`, `Pytorch` nos ofrece todo lo que necesitamos para diseñar y entrenar `redes neuronales`. Puedes aprender más sobre `autograd` [aquí](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py). Sin embargo, si queremos entrenar redes muy grandes o utilizar datasets muy grandes (o ambas), el proceso de entrenamiento será muy lento. Es aquí donde entra en juego el último elemento que hace de `Pytorch` lo que es. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La última pieza que nos falta explorar es la posibilidad de ejecutar nuestro código en `GPU`. Para ello, solo tenemos que crear nuestros `tensores` en la `GPU` y ejecutar las operaciones de la misma manera. ¡Super sencillo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0285e-01, -1.0678e-01, -1.7388e-01],\n",
       "        [-4.4772e-01,  2.6374e-01,  2.8962e-01],\n",
       "        [ 3.0987e-01, -2.9449e-01, -4.0236e-04]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3, device=\"cuda\")\n",
    "y = torch.randn(3, 3, device=\"cuda\")\n",
    "\n",
    "x * y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes son todas formas válidas de crear un `tensor` en la `GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4112, -0.0476, -0.4308],\n",
       "        [-0.2315, -1.1937,  0.0723],\n",
       "        [ 1.5994, -0.0311,  0.1895]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")           # device = \"cuda\" también sirve\n",
    "\n",
    "x = torch.randn(3, 3, device=device)    # crea el tensor en la GPU\n",
    "\n",
    "x = torch.randn(3, 3)\n",
    "x = x.to(device)                        # mueve el tensor a la GPU (menos eficiente)\n",
    "x = x.cuda()                            # mueve el tensor a la GPU (menos eficiente)    \n",
    "\n",
    "device = \"cuda:0\"                       # selecciona la primera GPU, si hay más de una - \"cuda:1\", \"cuda:2\", etc.\n",
    "x = torch.randn(3, 3, device=device)   \n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes copiar un tensor de la `GPU` a la `CPU` con la función `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "x = x.cpu()\n",
    "x = x.to(\"cpu\")\n",
    "x = x.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente ejemplo ilustra porque es importante ejecutar nuestro código en `GPU`. En este caso, vamos a calcular el tiempo que tarda en ejecutarse la multiplicación de dos matrices grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 90.3 ms, sys: 165 ms, total: 256 ms\n",
      "Wall time: 27.9 ms\n"
     ]
    }
   ],
   "source": [
    "# en cpu\n",
    "\n",
    "x = torch.randn(10000,10000)\n",
    "y = torch.randn(10000,10000)\n",
    "\n",
    "%time z = x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 17.6 ms, total: 17.6 ms\n",
      "Wall time: 17.6 ms\n"
     ]
    }
   ],
   "source": [
    "# en gpu\n",
    "\n",
    "x = torch.randn(10000,10000).cuda()\n",
    "y = torch.randn(10000,10000).cuda()\n",
    "\n",
    "%time z = x*y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues ahora que ya conocemos los conceptos básicos de `Pytorch` vamos a ver como podemos diseñar redes neuronales. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos secuenciales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma más sencilla de definir una `red neuronal` en `Pytorch` es utilizando la clase `Sequentail`. Esta clase nos permite definir una secuencia de capas, que se aplicarán de manera secuencial (las salidas de una capa serán la entrada de la siguiente). Vamos a definir un `Perceptrón Multicapa (MLP)`.\n",
    "\n",
    "> Puedes aprender más sobre `Perceptrones Multicapa` en este [post](https://www.sensiocoders.com/blog/023_mlp_backprop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in, H, D_out = 784, 100, 10\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo anterior es un `MLP` con 784 entradas, una capa oculta de 100 neuronas y 10 salidas. Para *ejectuar* el modelo, podemos llamarlo como de si una función se tratase, pasando como argumento el tensor con los *inputs*.\n",
    "\n",
    "> La capa de tipo `Linear` espera un tensor de 2 dimensiones, en la cual la primera es la dimensión del `batch` que puedes ser arbitraria y la segunda tiene que coincidir con el número de neuronas especificado, en nuestro ejemplo 784 en la primera capa y 100 en la segunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(torch.randn(64, 784))\n",
    "outputs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera que hemos visto antes con los tensores, podemos enviar nuestro modelo a la `GPU` para acelerar las operaciones internas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 10]), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "x = torch.randn(64, 784).cuda()\n",
    "\n",
    "outputs = model(x)\n",
    "outputs.shape, outputs.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos personalizados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien los modelos secuenciales son útiles para definir redes neuronales sencillas, en la práctica casi siempre necesitaremos definir redes más complejas. Para ello, podemos definir nuestras propias clases que hereden de la clase `Module` de `Pytorch`. Esta clase nos permite definir modelos de manera más flexible, ya que nos permite diseñar la lógica de ejecución del modelo a nuestro gusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, D_in=784, H=100, D_out=10):\n",
    "        \n",
    "        # llamamos al constructor de la clase madre\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # definimos nuestras capas\n",
    "        self.fc1 = torch.nn.Linear(D_in, H)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "    # lógica para calcular las salidas de la red\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, necesitamos definir una nueva clase que herede de la clase `torch.nn.Module`. Esta clase madre aportará toda la funcionalidad esencial que necesita una `red neuronal` (soporte GPU, iterar por sus parámeteros, etc). Luego, en esta clase necesitamos definir mínimos dos funciones: \n",
    "\n",
    "- `init`: en el constructor llamaremos al constructor de la clase madre y después definiremos todas las capas que querramos usar en la red.\n",
    "- `forward`: en esta función definimos toda la lógica que aplicaremos desde que recibimos los inputs hasta que devolvemos los outputs.\n",
    "\n",
    "En el ejemplo anterior simplemente hemos replicado la misma red (puedes conseguir el mismo efecto usando la clase `Sequential`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(784, 100, 10)\n",
    "outputs = model(torch.randn(64, 784))\n",
    "outputs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilando modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las novedades que `Pytorch 2.0` introduce es la posibilidad de `compilar` el modelo. Esto le permite *analizar* nuestro modelo para su optimización, consiguiendo así un mejor rendimiento durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compiled = torch.compile(model) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes aprender más sobre esta funcionalidad [aquí](https://pytorch.org/get-started/pytorch-2.0/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de entrenar una red neuronal, necesitamos un conjunto de datos sobre el que entrenar. Para ello, `Pytorch` nos ofrece funcionalidad para su creación e iteración de manera optimizada. Vamos a ver un ejemplo usando el conjunto de datos `MNIST`, que podemos descargar usando `Scikit-Learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 28, 28), (70000,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# mnist = fetch_openml('mnist_784', version=1)\n",
    "# X, Y = mnist[\"data\"].values.astype(float).reshape(-1, 28, 28) / 255., mnist[\"target\"].values.astype(int)\n",
    "# np.savez_compressed(\"mnist.npz\", X=X, y=Y)\n",
    "\n",
    "# la descarga puede tardar un rato, así que te recomiendo comentar las líneas anteriores después\n",
    "# de ejecutarlas la primera vez y descomentar las siguientes para cargar los datos desde el disco\n",
    "\n",
    "X, Y = np.load(\"mnist.npz\")[\"X\"], np.load(\"mnist.npz\")[\"y\"]\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "r, c = 3, 5\n",
    "fig = plt.figure(figsize=(2*c, 2*r))\n",
    "for _r in range(r):\n",
    "    for _c in range(c):\n",
    "        plt.subplot(r, c, _r*c + _c + 1)\n",
    "        ix = random.randint(0, len(X)-1)\n",
    "        plt.imshow(X[ix], cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(y[ix])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este dataset consiste en imágenes de dígitos manuscritos (del 0 al 9) con su correspondiente etiqueta, un dataset muy útil para aprender a entrenar redes neuronales, en concreto para clasificación de imágenes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El `DataLoader`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `DataLoader` es un objeto que nos permite iterar nuestro dataset en `batches` de manera eficiente. Podemos pasarle como argumento cualquier iterador, desde una lista de `Python` hasta un `array` de `NumPy` o un `tensor` de `Pytorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(X, batch_size=100)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene varias opciones interesantes que nos permitirán mejorar la eficiencia de nuestro entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    X,                      # datos                 \n",
    "    batch_size=100,         # tamaño del batch, número de imágenes por iteración\n",
    "    shuffle=True,           # barajamos los datos antes de cada epoch\n",
    "    num_workers=4,          # número de procesos que se lanzan para cargar los datos (número de cores de la CPU para carga en paralelo)\n",
    "    pin_memory=True,        # si tenemos una GPU, los datos se cargan en la memoria de la GPU\n",
    "    collate_fn=None,        # función para combinar los datos de cada batch\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El `Dataset` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien el `dataloader` es capaz de trabajar con cualquier iterador, `Pytorch` nos ofrece una clase base para crear nuestros propios datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    # constructor\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.Y = torch.tensor(Y).long()\n",
    "    # cantidad de muestras en el dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    # devolvemos el elemento `ix` del dataset\n",
    "    def __getitem__(self, ix):\n",
    "        return self.X[ix], self.Y[ix]\n",
    "    # opcionalmente, podemos definir una función para generar un batch\n",
    "    def collate_fn(self, batch):\n",
    "        x, y = [], []\n",
    "        for _x, _y in batch:\n",
    "            x.append(_x)\n",
    "            y.append(_y)\n",
    "        return torch.stack(x).view(len(batch), -1), torch.stack(y) # estiramos las imágenes en una dimensión"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello crearemos una nueva clase que hereda de `torch.utils.data.Dataset`, en la cual definiremos estas tres funciones: \n",
    "\n",
    "- `__init__`: el constructor\n",
    "- `__len__`: devuelve el número de muestras en el dataset\n",
    "- `__getitem__`: devuelve una muestra en concreto del dataset\n",
    "\n",
    "Cada vez que nuestro `dataloader` necesite una nueva muestra, llamará a la función `__getitem__` pasándole el índice de la muestra que necesita. Aquí podremos definir cualquier lógica de carga y procesado de datos (por ejemplo, leer imágenes y aplicar transformaciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(X, Y)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100)\n",
    "\n",
    "for batch in dataloader:\n",
    "    x, y = batch\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, collate_fn=dataset.collate_fn)\n",
    "\n",
    "for batch in dataloader:\n",
    "    x, y = batch\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha llegado el momento de ver cómo podemos entrenar nuestro modelo con el dataset que hemos creado. Empezaremos con un ejemplo mínimo, en el que entrenaremos nuestro `MLP` con el dataset `MNIST`.\n",
    "\n",
    "![](https://media.licdn.com/dms/image/C4D12AQFKRQOp_aXz0g/article-cover_image-shrink_600_2000/0/1577211633664?e=2147483647&v=beta&t=pZ5TdXalXICIqPXTDBX6NP-CYlGS3wE2Kn6y1XiYjHI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además del modelo y los datos necesitaremos dos elementos más para el enterenamiento:\n",
    "\n",
    "- Una función de pérdida (medirá el error del modelo)\n",
    "- Un optimizador (se encargará de actualizar los parámetros del modelo para minimizar la función de pérdida)\n",
    "\n",
    "En ambos casos, `Pytorch` nos ofrece una amplia gama de opciones, que podemos consultar en la [documentación](https://pytorch.org/docs/stable/nn.html#loss-functions).\n",
    "\n",
    "> Puedes aprender más sobre estos conceptos [aquí](https://www.sensiocoders.com/blog/013_perceptron2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/5\n",
      "loss: 2.3083 [  100/70000]\n",
      "loss: 0.4708 [10100/70000]\n",
      "loss: 0.4804 [20100/70000]\n",
      "loss: 0.3436 [30100/70000]\n",
      "loss: 0.2486 [40100/70000]\n",
      "loss: 0.2684 [50100/70000]\n",
      "loss: 0.1554 [60100/70000]\n",
      "epoch: 2/5\n",
      "loss: 0.1684 [  100/70000]\n",
      "loss: 0.2374 [10100/70000]\n",
      "loss: 0.2315 [20100/70000]\n",
      "loss: 0.2300 [30100/70000]\n",
      "loss: 0.1569 [40100/70000]\n",
      "loss: 0.1538 [50100/70000]\n",
      "loss: 0.0832 [60100/70000]\n",
      "epoch: 3/5\n",
      "loss: 0.1205 [  100/70000]\n",
      "loss: 0.1479 [10100/70000]\n",
      "loss: 0.1593 [20100/70000]\n",
      "loss: 0.2072 [30100/70000]\n",
      "loss: 0.1202 [40100/70000]\n",
      "loss: 0.1048 [50100/70000]\n",
      "loss: 0.0513 [60100/70000]\n",
      "epoch: 4/5\n",
      "loss: 0.1045 [  100/70000]\n",
      "loss: 0.1018 [10100/70000]\n",
      "loss: 0.1186 [20100/70000]\n",
      "loss: 0.1899 [30100/70000]\n",
      "loss: 0.1018 [40100/70000]\n",
      "loss: 0.0798 [50100/70000]\n",
      "loss: 0.0350 [60100/70000]\n",
      "epoch: 5/5\n",
      "loss: 0.0954 [  100/70000]\n",
      "loss: 0.0766 [10100/70000]\n",
      "loss: 0.0974 [20100/70000]\n",
      "loss: 0.1619 [30100/70000]\n",
      "loss: 0.0900 [40100/70000]\n",
      "loss: 0.0665 [50100/70000]\n",
      "loss: 0.0270 [60100/70000]\n"
     ]
    }
   ],
   "source": [
    "# instanciamos nuestro dataset\n",
    "dataset = Dataset(X, Y)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, collate_fn=dataset.collate_fn)\n",
    "# instanciamos nuestro modelo\n",
    "model = Model(784, 100, 10)\n",
    "# definimos la función de pérdida y el optimizador\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# bucle de entrenamiento\n",
    "epochs = 5\n",
    "for e in range(1, epochs+1):\n",
    "    print(f\"epoch: {e}/{epochs}\")\n",
    "    for batch_ix, (x, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()           # reseteamos los gradientes\n",
    "        outputs = model(x)              # calculamos las salidas\n",
    "        loss = criterion(outputs, y)    # calculamos la pérdida\n",
    "        loss.backward()                 # calculamos los gradientes\n",
    "        optimizer.step()                # actualizamos los parámetros\n",
    "        if batch_ix % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_ix + 1) * len(x)\n",
    "            print(f\"loss: {loss:.4f} [{current:>5d}/{len(dataset):>5d}]\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo va según lo planeado, deberíamos ver como la función de pérdida va disminuyendo a medida que el modelo va aprendiendo. En un ejemplo real, sin embargo, haremos un entrenamiento más sofisticado, en el que dividiremos nuestro dataset en dos partes: una para entrenar y otra para validar el modelo; y también trackearemos diversas métricas para evaluar el rendimiento del modelo (aunque en un caso real debería usar algun sistema de trackeado como `Weights and Biases` o `MLFLow`).\n",
    "\n",
    "> Puedes aprender más sobre este tema [aquí](https://www.sensiocoders.com/blog/030_data_splitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/5\n",
      "loss: 2.3071 [  100/    2]\n",
      "loss: 0.4796 [10100/    2]\n",
      "loss: 0.4902 [20100/    2]\n",
      "loss: 0.3303 [30100/    2]\n",
      "loss: 0.2502 [40100/    2]\n",
      "loss: 0.2880 [50100/    2]\n",
      "val_loss: 0.2448 val_acc: 0.9294\n",
      "epoch: 2/5\n",
      "loss: 0.2043 [  100/    2]\n",
      "loss: 0.2335 [10100/    2]\n",
      "loss: 0.2635 [20100/    2]\n",
      "loss: 0.2312 [30100/    2]\n",
      "loss: 0.1590 [40100/    2]\n",
      "loss: 0.1796 [50100/    2]\n",
      "val_loss: 0.1758 val_acc: 0.9482\n",
      "epoch: 3/5\n",
      "loss: 0.1482 [  100/    2]\n",
      "loss: 0.1760 [10100/    2]\n",
      "loss: 0.1966 [20100/    2]\n",
      "loss: 0.1938 [30100/    2]\n",
      "loss: 0.1096 [40100/    2]\n",
      "loss: 0.1193 [50100/    2]\n",
      "val_loss: 0.1384 val_acc: 0.9610\n",
      "epoch: 4/5\n",
      "loss: 0.1201 [  100/    2]\n",
      "loss: 0.1345 [10100/    2]\n",
      "loss: 0.1524 [20100/    2]\n",
      "loss: 0.1783 [30100/    2]\n",
      "loss: 0.0874 [40100/    2]\n",
      "loss: 0.0957 [50100/    2]\n",
      "val_loss: 0.1175 val_acc: 0.9659\n",
      "epoch: 5/5\n",
      "loss: 0.1024 [  100/    2]\n",
      "loss: 0.1105 [10100/    2]\n",
      "loss: 0.1261 [20100/    2]\n",
      "loss: 0.1545 [30100/    2]\n",
      "loss: 0.0714 [40100/    2]\n",
      "loss: 0.0852 [50100/    2]\n",
      "val_loss: 0.1041 val_acc: 0.9698\n"
     ]
    }
   ],
   "source": [
    "# instanciamos nuestro dataset\n",
    "dataset = {\n",
    "    \"train\": Dataset(X[:60000], Y[:60000]),\n",
    "    \"val\": Dataset(X[60000:], Y[60000:])\n",
    "}\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=100, collate_fn=dataset['train'].collate_fn),\n",
    "    'val': torch.utils.data.DataLoader(dataset['val'], batch_size=100, collate_fn=dataset['val'].collate_fn)\n",
    "}\n",
    "# instanciamos nuestro modelo\n",
    "model = Model(784, 100, 10)\n",
    "# definimos la función de pérdida y el optimizador\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# bucle de entrenamiento\n",
    "epochs = 5\n",
    "for e in range(1, epochs+1):\n",
    "    print(f\"epoch: {e}/{epochs}\")\n",
    "    # entrenamiento\n",
    "    model.train()\n",
    "    for batch_ix, (x, y) in enumerate(dataloader['train']):\n",
    "        optimizer.zero_grad()           \n",
    "        outputs = model(x)              \n",
    "        loss = criterion(outputs, y)    \n",
    "        loss.backward()                 \n",
    "        optimizer.step()                \n",
    "        if batch_ix % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_ix + 1) * len(x)\n",
    "            print(f\"loss: {loss:.4f} [{current:>5d}/{len(dataset):>5d}]\")\n",
    "    # validación\n",
    "    model.eval()                \n",
    "    val_loss, val_acc = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_ix, (x, y) in enumerate(dataloader['val']):\n",
    "            outputs = model(x)              \n",
    "            loss = criterion(outputs, y)    \n",
    "            val_loss.append(loss.item())\n",
    "            val_acc.append((outputs.argmax(1) == y).float().mean().item())\n",
    "    print(f\"val_loss: {np.mean(val_loss):.4f} val_acc: {np.mean(val_acc):.4f}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar podemos poner el modelo en modo entrenamiento o evaluación con las funciones `train` y `eval`. Esto es importante ya que algunas capas (como `Dropout` o `BatchNorm`) tienen comportamientos diferentes en cada modo. Además, durante la validación, usamos el contexto `torch.no_grad` para que no se calcule el gradiente, ya que no lo necesitamos (esto hará que el entrenamiento sea más rápido)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consejos para mejores prestaciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo sencillo todo va rápido, pero en casos reales puede que tengamos que esperar mucho tiempo a que el modelo se entrene. Para ello, podemos hacer algunas cosas para mejorar la velocidad de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/5\n",
      "loss: 2.3098 [ 1000/60000]\n",
      "loss: 1.7387 [11000/60000]\n",
      "loss: 1.1731 [21000/60000]\n",
      "loss: 0.8057 [31000/60000]\n",
      "loss: 0.6480 [41000/60000]\n",
      "loss: 0.4715 [51000/60000]\n",
      "val_loss: 0.4343 val_acc: 0.8917\n",
      "epoch: 2/5\n",
      "loss: 0.4613 [ 1000/60000]\n",
      "loss: 0.3864 [11000/60000]\n",
      "loss: 0.3995 [21000/60000]\n",
      "loss: 0.3641 [31000/60000]\n",
      "loss: 0.3603 [41000/60000]\n",
      "loss: 0.3143 [51000/60000]\n",
      "val_loss: 0.3096 val_acc: 0.9154\n",
      "epoch: 3/5\n",
      "loss: 0.3157 [ 1000/60000]\n",
      "loss: 0.2750 [11000/60000]\n",
      "loss: 0.3310 [21000/60000]\n",
      "loss: 0.3152 [31000/60000]\n",
      "loss: 0.3120 [41000/60000]\n",
      "loss: 0.2451 [51000/60000]\n",
      "val_loss: 0.2718 val_acc: 0.9231\n",
      "epoch: 4/5\n",
      "loss: 0.2578 [ 1000/60000]\n",
      "loss: 0.2539 [11000/60000]\n",
      "loss: 0.2705 [21000/60000]\n",
      "loss: 0.2583 [31000/60000]\n",
      "loss: 0.2628 [41000/60000]\n",
      "loss: 0.2335 [51000/60000]\n",
      "val_loss: 0.2404 val_acc: 0.9321\n",
      "epoch: 5/5\n",
      "loss: 0.2486 [ 1000/60000]\n",
      "loss: 0.2486 [11000/60000]\n",
      "loss: 0.2587 [21000/60000]\n",
      "loss: 0.2530 [31000/60000]\n",
      "loss: 0.2613 [41000/60000]\n",
      "loss: 0.2532 [51000/60000]\n",
      "val_loss: 0.2203 val_acc: 0.9358\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"train\": Dataset(X[:60000], Y[:60000]), # 60.000 imágenes para entrenamiento\n",
    "    \"val\": Dataset(X[60000:], Y[60000:])    # 10.000 imágenes para validación\n",
    "}\n",
    "# aumentamos el tamaño del batch para aprovechar la GPU, carga en paralelo y movemos los datos a la GPU\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=1000, shuffle=True, num_workers=4, pin_memory=True, collate_fn=dataset['train'].collate_fn),\n",
    "    'val': torch.utils.data.DataLoader(dataset['val'], batch_size=1000, num_workers=4, pin_memory=True, collate_fn=dataset['val'].collate_fn)\n",
    "}\n",
    "model = Model(784, 100, 10)\n",
    "# compilamos el modelo\n",
    "# model = torch.compile(model)\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "# torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "# movemos el modelo a la GPU\n",
    "model.cuda()                                                                   \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "epochs = 5\n",
    "for e in range(1, epochs+1):\n",
    "    print(f\"epoch: {e}/{epochs}\")\n",
    "    # entrenamiento\n",
    "    model.train()\n",
    "    for batch_ix, (x, y) in enumerate(dataloader['train']):\n",
    "        x, y = x.cuda(), y.cuda()                                                   # movemos los datos a la GPU\n",
    "        optimizer.zero_grad()    \n",
    "        with torch.autocast(device_type='cuda', dtype=torch.bfloat16):              # automatic mixed precision\n",
    "            outputs = model(x)              \n",
    "            loss = criterion(outputs, y)    \n",
    "        loss.backward()                 \n",
    "        optimizer.step()                \n",
    "        if batch_ix % 10 == 0:\n",
    "            loss, current = loss.item(), (batch_ix + 1) * len(x)\n",
    "            print(f\"loss: {loss:.4f} [{current:>5d}/{len(dataset['train']):>5d}]\")\n",
    "    # validación\n",
    "    model.eval()                \n",
    "    val_loss, val_acc = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_ix, (x, y) in enumerate(dataloader['val']):\n",
    "            x, y = x.cuda(), y.cuda()                                               # movemos los datos a la GPU\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16):          # automatic mixed precision\n",
    "                outputs = model(x)              \n",
    "                loss = criterion(outputs, y)    \n",
    "            val_loss.append(loss.item())\n",
    "            val_acc.append((outputs.argmax(1) == y).float().mean().item())\n",
    "    print(f\"val_loss: {np.mean(val_loss):.4f} val_acc: {np.mean(val_acc):.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de entrenar modelos muy grandes, es posible hacerlo en varias `GPUs` para acelerar el entrenamiento. Puedes aprender más sobre este tema [aquí](https://www.sensiocoders.com/blog/070_pytorch_distributed).\n",
    "\n",
    "Por último, te dejo también mi [receta](https://www.sensiocoders.com/blog/033_receta_entrenamiento) de entrenamiento de redes neuronales, que puedes seguir a la hora de diseñar y entrenar tus modelos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportando modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado tu modelo es posible que quieras exportarlo para usarlo en otro proyecto o incluso en producción. Para ello, `Pytorch` nos ofrece diferents opciones para exportar nuestro modelo. La forma más sencilla es usar la función `torch.save`, que nos permite guardar el modelo en un fichero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez guardado lo podrás leer desde cualquier otro proyecto usando la función `torch.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = torch.load('model.pth')\n",
    "loaded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una alternativa más eficiente y flexible consiste en exporar el `state_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model.ckpt')\n",
    "\n",
    "model = Model(784, 100, 10)\n",
    "model.load_state_dict(torch.load('model.ckpt'))\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además del modelo podemos guardar el `state_dict` del optimizador para poder continuar el entrenamiento en otro momento, por lo que es muy útil para guardar `checkpoints`.\n",
    "\n",
    "En ambos casos vas a necesitar el mismo código usado a la hora de exportar el modelo para poder cargarlo. Esto puede ser un inconveniente en muchos casos, por lo que una buena alternativa es usar `torch.script` para serializar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model) \n",
    "model_scripted.save('model_scripted.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=Model\n",
       "  (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "  (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "  (fc2): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.jit.load('model_scripted.pt')\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta aproximación permite desacoplar el código de los pesos del modelo, sin embargo vamos a seguir necesitando `Pytorch` para poder cargar el modelo (lo cual no siempre será posible en función del entorno de producción del modelo). Para ello podemos usar `ONNX` para exportar el modelo a un formato estándar que puede ser usado por cualquier framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Diagnostic Run torch.onnx.export version 2.0.0.dev20230213+cu117 =======\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    model.cpu(), \n",
    "    torch.randn(10, 784), \n",
    "    'model.onnx', \n",
    "    opset_version=11, \n",
    "    input_names=['input'], \n",
    "    output_names=['output'], \n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx \n",
    "\n",
    "onnx_model = onnx.load('model.onnx')\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `Python` podemos usar la librería `onnxruntime` para cargar el modelo y usarlo en producción, en los que no es necesario que `Pytorch` esté instalado (funciona directamente con `NumPy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession('model.onnx')\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: torch.randn(16, 784).numpy()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "ort_outs[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecosistema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pytorch` es un proyecto muy activo, con una gran comunidad de desarrolladores que contribuyen a su mejora. Además, cuenta con una gran cantidad de librerías que nos permiten extender sus funcionalidades. Algunos ejemplos son:\n",
    "\n",
    "- `Torchvision`: librería de visión por computador para `Pytorch`, puedes aprender más sobre ella [aquí](https://www.sensiocoders.com/blog/055_torchvision).\n",
    "- `Torchtext`: librería de procesamiento de lenguaje natural para `Pytorch`, puedes aprender más sobre ella [aquí](https://www.sensiocoders.com/blog/056_torchtext).\n",
    "- `Huggingface`: gran ecosistema conocido por su librería de `transformers` pero que poco a poco a evolucionado incluyendo muchas otras funcionalidades, puedes aprender más sobre ella [aquí](https://www.sensiocoders.com/blog/105_hf_intro).\n",
    "- `Torhcmetrics`: librería de métricas para `Pytorch`.\n",
    "\n",
    "De entre todas ellas, destacaría [`Pytorch Lightning`](https://lightning.ai/docs/pytorch/stable/), una librería que nos hace la vida más fácil a la hora de entrenar modelos y que veremos en detalle en el siguiente post ya que también acaba de lanzar su versión 2.0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
