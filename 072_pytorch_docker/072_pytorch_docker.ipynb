{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4453ecd4",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/072_pytorch_docker_/072_pytorch_docker_.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a8999",
   "metadata": {},
   "source": [
    "# Pytorch NGC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e83ae4",
   "metadata": {},
   "source": [
    "En los posts anteriores hemos visto muchos trucos para optimizar nuestro código en Pytorch, sin embargo no nos hemos preocupado por la instalación del mismo. En este post vamos a aprender a usar una versión de `Pytorch` optimizada que en alguna ocasión nos dará un pequeño extra de performance. Para ello vamos a usar `Docker`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db69ad4",
   "metadata": {},
   "source": [
    "## ¿Qué es `Docker`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3cd217",
   "metadata": {},
   "source": [
    "[`Docker`](https://www.docker.com/) es una tecnología que nos permite crear entornos de software paquetizados y aisaldos del resto de componenetes en un sistema operativo. Similar en espíritu a una máquina virtual, o a los entornos virtuales de `Python`, con `Docker` podremos crear imágenes (que contendrán nuestro código y sus dependencias) que serán ejectuadas en contenedores (el entorno aislado). De esta manera estremos seguros que nuestro código funcionará en cualquier plataforma siempre y cuando `Docker` esté instalado.\n",
    "\n",
    "![](https://thingsolver.com/wp-content/uploads/pasted-image-0-768x452-1.png)\n",
    "\n",
    "No es el objetivo de este post explicar en detalle cómo trabajar con `Docker`, para ello existen multitud de tutoriales en internet. Pero sí que vamos a ver como podemos aplicar esta tecnlogía a la hora de trabajar con `Pytorch`.\n",
    "\n",
    "> ⚠️ Si bien puedes instalar `Docker` en cualquier sistema operativo, lo que vamos a ver en este post sólo funciona en Linux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fcdc2",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef2114",
   "metadata": {},
   "source": [
    "Para poder trabajar con `Pytorch` y `Docker` necesitamos instalar las siguientes dependencias:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f092f15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T13:43:42.114525Z",
     "start_time": "2021-06-29T13:43:42.108116Z"
    }
   },
   "source": [
    "- [`Docker`](https://docs.docker.com/engine/install/ubuntu/)\n",
    "- [`nvidia-docker`](https://github.com/NVIDIA/nvidia-docker) (para que `Docker` puedas usar nuestra `GPU`)\n",
    "- Opcionalmente, instala [`docker-compose`](https://docs.docker.com/compose/install/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11bb85f",
   "metadata": {},
   "source": [
    "## Ejecutando `Jupyter Notebooks` en `Docker`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77151cc",
   "metadata": {},
   "source": [
    "Lo primero que vamos a ver es como ejecutar una imágen de `Docker` con `Python`. Para ello, una vez hayas instalado `Docker`, ejecuta el siguiente comando en la terminal:\n",
    "\n",
    "```\n",
    "docker run -it python:3.9-slim python\n",
    "```\n",
    "\n",
    "Esto descargará la imágen `python:3.9-slim` de [`dockerhub`](https://hub.docker.com/) si no la encuentra en el sistema y luego ejecutará el comando `python`. Al haber indicado a `Docker` que lo ejecute en modo interactivo (-it) se abrirá un terminal de `Python` dentro del contenedor. Como puedes ver, si necesitas una versión de `Python` diferente simplemente tendrás que indicarle el `tag` apropiado.\n",
    "\n",
    "Para abrir un `notebook` puedes usar el comando siguiente:\n",
    "\n",
    "```\n",
    "docker run python:3.9-slim jupyter notebook\n",
    "```\n",
    "\n",
    "sin embargo esto dará un error, y es que la imágen usada no tiene `jupyter notebook` instalado. Tenemos dos opciones, usar una imágen diferente que sí lo tenga o bien crearnos nuestra propia imágen. Para ello, crea un archivo llamado `Dockerfile` con el siguiente contenido:\n",
    "\n",
    "\n",
    "```\n",
    "FROM python:3.9-slim\n",
    "\n",
    "RUN pip install jupyter\n",
    "\n",
    "WORKDIR /workspace\n",
    "``` \n",
    "\n",
    "Ahora puedes crear tu propia imágen con el comando\n",
    "\n",
    "```\n",
    "docker build -t jupyter .\n",
    "```\n",
    "\n",
    "Y ejectuarla de la siguiente manera\n",
    "\n",
    "```\n",
    "docker run jupyter jupyter notebook --allow-root\n",
    "```\n",
    "\n",
    "Sin embargo, esto seguirá sin funcionar. El motivo es que nuestra imágen está siendo ejectuada en un entorno aisaldo, en el que no existe un navegador ni tampoco forma de poder conectarnos. Para solventar este problema ejecutaremos el comando\n",
    "\n",
    "```\n",
    "docker run -p 8888:8888 jupyter  jupyter notebook --allow-root --no-browser --ip=0.0.0.0\n",
    "```\n",
    "\n",
    "Ahora ya podrás usar tus notebooks !!! Sin embargo, si creas un nuevo notebook y paras el contenedor, al volver a abrirlo habrá desaparecido. Esto es debido a que, como ya hemos comentado, nuestro código se ejecuta en un entorno aislado por lo que no tendremos persistencia en nuestros archivos. Para solventarlo, usarmos el conceptro de `volumes` (carpetas compartidas entre nuestro ordenador y `Docker`).\n",
    "\n",
    "```\n",
    "docker run -p 8888:8888 -v ${PWD}/ipynbs:/workspace/ipynbs jupyter  jupyter notebook --allow-root --no-browser --ip=0.0.0.0\n",
    "```\n",
    "\n",
    "Con esto tenemos todo lo necesario para trabajar con notebooks en `Docker`. Te recomiendo como último paso utilizas `docker-compose` ya que tener que ejecutar un comando tan largo en la consola puede convertirse en algo tedioso. `Docker-compose` es una herramienta que nos permite ejecutar nuestros contenedores usando archivos de configuración (entre muchas otras cosas que no veremos aquí). Para ello, crea un archivo llamado `docker-compose.yml` con el siguiente contenido:\n",
    "\n",
    "```\n",
    "version: \"3.0\"\n",
    "\n",
    "services:\n",
    "  jupyter:\n",
    "    container_name: jupyter\n",
    "    image: jupyter\n",
    "    build: .\n",
    "    ports:\n",
    "      - 8888:8888\n",
    "    volumes:\n",
    "      - ./ipynbs:/workspace/ipynbs\n",
    "    command: jupyter notebook --allow-root --ip=0.0.0.0 --no-browser \n",
    "```\n",
    "\n",
    "Puedes crear tus imágenes con el comando `docker-compose build`, ejecutar el contenedor con `docker-compose up` y pararlo con `docker-compose down`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293d4ed",
   "metadata": {},
   "source": [
    "## `Pytorch` en `Docker`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa46eeb",
   "metadata": {},
   "source": [
    "Vamos ahora a ver cómo podemos trabajar con `Pytorch` en `Docker`. Si bien podemos hacer como antes e instalar `Pytorch` en nuestra imágen, ahora haremos lo contrario y usaremos una imágen ya hecha. El motivo es que podemos encontrar imágenes en internet con instalaciones optimizadas que nos pueden dar un extra de performance en ciertos casos gracias al acceso a nuevas características o funcionalidad no implementadas en la distribución oficial que podemos instalar con `conda`. Un repositorio muy recomendado en [`ngc`](https://ngc.nvidia.com/catalog/containers?orderBy=scoreDESC&pageNumber=0&query=pytorch&quickFilter=&filters=), en el que podemos encontrar instalaciones de `Pytorch` opimizadas por los propios ingenieros de `NVIDIA`. Puedes ejecutar un notebook con esta imágen con el siguiente `docker-compose`.\n",
    "\n",
    "```\n",
    "version: \"2.3\"\n",
    "\n",
    "services:\n",
    "  pytorch-ngc:\n",
    "    runtime: nvidia\n",
    "    container_name: pytorch-ngc\n",
    "    image: nvcr.io/nvidia/pytorch:21.06-py3\n",
    "    ipc: host\n",
    "    ports:\n",
    "      - 8888:8888\n",
    "    volumes:\n",
    "      - ./ipynbs:/workspace\n",
    "      - ./data:/workspace/data\n",
    "    environment:\n",
    "      - NVIDIA_VISIBLE_DEVICES=all\n",
    "    command: jupyter notebook --allow-root --ip=0.0.0.0 --no-browser --NotebookApp.token=abc123\n",
    "```\n",
    "\n",
    "Aunque es muy probable que en algún momento quieras customizar esta imágen para incluir alguna librería extra, como por ejemplo `Pytorch Lightning` (si bien existe una imágen con esta librería instalada, vamos a ver un ejemplo de cómo puedes añadir tus propias dependencias). Para ello, ya sabes que tienes que crear un `Dockerfile`.\n",
    "\n",
    "```\n",
    "FROM nvcr.io/nvidia/pytorch:21.06-py3\n",
    "\n",
    "RUN pip install --upgrade pip && pip install \\\n",
    "    pytorch-lightning \\\n",
    "    timm \\\n",
    "    pytorch-segmentation-models\n",
    "\n",
    "WORKDIR /workspace\n",
    "```\n",
    "\n",
    "Y luegos puedes usar el siguiente `docker-compose`.\n",
    "\n",
    "```\n",
    "version: \"2.3\"\n",
    "\n",
    "services:\n",
    "  pytorch-ngc:\n",
    "    runtime: nvidia\n",
    "    container_name: pytorch-ngc\n",
    "    image: pytorch-ngc\n",
    "    build: .\n",
    "    ipc: host\n",
    "    ports:\n",
    "      - 8888:8888\n",
    "    volumes:\n",
    "      - ./ipynbs:/workspace\n",
    "      - ./data:/workspace/data\n",
    "    environment:\n",
    "      - NVIDIA_VISIBLE_DEVICES=all\n",
    "    command: jupyter notebook --allow-root --ip=0.0.0.0 --no-browser --NotebookApp.token=abc123\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e648f75",
   "metadata": {},
   "source": [
    "Una vez hayas jugado un poco con todo lo visto hasta ahora, puedes intentar abrir este mismo notebook con `Docker` y ejectuar el siguiente código para entrenar una red neuronal. Para ello necesitarás descargar el dataset [EuroSAT](https://github.com/phelber/eurosat) y colocarlo en la carpeta `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0ef4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "937b94d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fdebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images and labels ...\n",
      "Number of images: 27000\n",
      "Generating train / val splits ...\n",
      "Training samples:  21600\n",
      "Validation samples:  5400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def setup(path='./data', test_size=0.2, random_state=42):\n",
    "\n",
    "    classes = sorted(os.listdir(path))\n",
    "\n",
    "    print(\"Generating images and labels ...\")\n",
    "    images, encoded = [], []\n",
    "    for ix, label in enumerate(classes):\n",
    "        _images = os.listdir(f'{path}/{label}')\n",
    "        images += [f'{path}/{label}/{img}' for img in _images]\n",
    "        encoded += [ix]*len(_images)\n",
    "    print(f'Number of images: {len(images)}')\n",
    "\n",
    "     # train / val split\n",
    "    print(\"Generating train / val splits ...\")\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "        images,\n",
    "        encoded,\n",
    "        stratify=encoded,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(\"Training samples: \", len(train_labels))\n",
    "    print(\"Validation samples: \", len(val_labels))\n",
    "    \n",
    "    return classes, train_images, train_labels, val_images, val_labels\n",
    "\n",
    "classes, train_images, train_labels, val_images, val_labels = setup('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd1cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import io \n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        img = io.imread(self.images[ix])[...,(3,2,1)]\n",
    "        img = torch.tensor(img / 4000, dtype=torch.float).clip(0,1).permute(2,0,1)  \n",
    "        label = torch.tensor(self.labels[ix], dtype=torch.long)        \n",
    "        return img, label\n",
    "    \n",
    "ds = {\n",
    "    'train': Dataset(train_images, train_labels),\n",
    "    'val': Dataset(val_images, val_labels)\n",
    "}\n",
    "\n",
    "batch_size = 1024\n",
    "dl = {\n",
    "    'train': torch.utils.data.DataLoader(ds['train'], batch_size=batch_size, shuffle=True, num_workers=20, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(ds['val'], batch_size=batch_size, shuffle=False, num_workers=20, pin_memory=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a96191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_outputs=10, use_amp=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('tf_efficientnet_b5', pretrained=True, num_classes=n_outputs)\n",
    "        self.use_amp = use_amp\n",
    "\n",
    "    def forward(self, x, log=False):\n",
    "        if log:\n",
    "            print(x.shape)\n",
    "        with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "            return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4433ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def step(model, batch, device):\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_hat = model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    acc = (torch.argmax(y_hat, axis=1) == y).sum().item() / y.size(0)\n",
    "    return loss, acc\n",
    "\n",
    "def train_amp(model, dl, optimizer, epochs=10, device=\"cpu\", use_amp = True, prof=None, end=0):\n",
    "    model.to(device)\n",
    "    hist = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    for e in range(1, epochs+1):\n",
    "        # train\n",
    "        model.train()\n",
    "        l, a = [], []\n",
    "        bar = tqdm(dl['train'])\n",
    "        stop=False\n",
    "        for batch_idx, batch in enumerate(bar):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # AMP\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                loss, acc = step(model, batch, device)\n",
    "            scaler.scale(loss).backward()\n",
    "            # gradient clipping \n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            l.append(loss.item())\n",
    "            a.append(acc)\n",
    "            bar.set_description(f\"training... loss {np.mean(l):.4f} acc {np.mean(a):.4f}\")\n",
    "            # profiling\n",
    "            if prof:\n",
    "                if batch_idx >= end:\n",
    "                    stop = True\n",
    "                    break\n",
    "                prof.step()  \n",
    "        hist['loss'].append(np.mean(l))\n",
    "        hist['acc'].append(np.mean(a))\n",
    "        if stop:\n",
    "            break\n",
    "        # eval\n",
    "        model.eval()\n",
    "        l, a = [], []\n",
    "        bar = tqdm(dl['val'])\n",
    "        with torch.no_grad():\n",
    "            for batch in bar:\n",
    "                loss, acc = step(model, batch, device)\n",
    "                l.append(loss.item())\n",
    "                a.append(acc)\n",
    "                bar.set_description(f\"evluating... loss {np.mean(l):.4f} acc {np.mean(a):.4f}\")\n",
    "        hist['val_loss'].append(np.mean(l))\n",
    "        hist['val_acc'].append(np.mean(a))\n",
    "        # log\n",
    "        log = f'Epoch {e}/{epochs}'\n",
    "        for k, v in hist.items():\n",
    "            log += f' {k} {v[-1]:.4f}'\n",
    "        print(log)\n",
    "        \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11e862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 1.4168 acc 0.7123: 100%|██████████| 22/22 [00:11<00:00,  1.88it/s]\n",
      "evluating... loss 7.0801 acc 0.3112: 100%|██████████| 6/6 [00:01<00:00,  3.25it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss 1.4168 acc 0.7123 val_loss 7.0801 val_acc 0.3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.1586 acc 0.9484: 100%|██████████| 22/22 [00:10<00:00,  2.05it/s]\n",
      "evluating... loss 0.4077 acc 0.8919: 100%|██████████| 6/6 [00:01<00:00,  3.26it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss 0.1586 acc 0.9484 val_loss 0.4077 val_acc 0.8919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.0436 acc 0.9868: 100%|██████████| 22/22 [00:10<00:00,  2.02it/s]\n",
      "evluating... loss 0.2022 acc 0.9483: 100%|██████████| 6/6 [00:01<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss 0.0436 acc 0.9868 val_loss 0.2022 val_acc 0.9483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "hist = train_amp(model, dl, optimizer, epochs=3, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89a9d5",
   "metadata": {},
   "source": [
    "## Scripts en Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da1b13f",
   "metadata": {},
   "source": [
    "Si bien trabajar con notebooks es muy conveniente en la mayoría de ocasiones, es posible que alternativamente quieras ejectuar un `script` dentro del contenedor de `Docker`. Puedes usar un `volume` para cargar tu código en el contenedor (ideal durante el desarrollo) o directamente copiar el `script` en la imágen (ideal si quieres compartir tu código o ejectuarlo en máquinas remotas).\n",
    "\n",
    "```\n",
    "FROM nvcr.io/nvidia/pytorch:21.06-py3\n",
    "\n",
    "RUN pip install --upgrade pip && pip install \\\n",
    "    pytorch-lightning \\\n",
    "    timm \\\n",
    "    segmentation-models-pytorch\n",
    "\n",
    "COPY ./main.py /workspace/main.py\n",
    "\n",
    "WORKDIR /workspace\n",
    "```\n",
    "\n",
    "Los datos los seguirás teniendo que cargar en un `volume` ya que meterlos en la imágen sería algo feo 😛, igualmente asegúrate de usar otro `volume` en el que guardar tus resultados.\n",
    "\n",
    "```\n",
    "version: \"2.3\"\n",
    "\n",
    "services:\n",
    "  pytorch-script:\n",
    "    runtime: nvidia\n",
    "    container_name: pytorch-script\n",
    "    image: pytorch-script\n",
    "    build: .\n",
    "    ipc: host\n",
    "    volumes:\n",
    "      - ./data:/workspace/data\n",
    "    environment:\n",
    "      - NVIDIA_VISIBLE_DEVICES=all\n",
    "    command: python main.py\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e55187",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ca191",
   "metadata": {},
   "source": [
    "`Docker` es una herramienta muy útil a la hora de gestionar nuestro código y sus dependencias. En este post hemos visto un ejemplo de cómo usarlo junto a `Pytorch`, pero lo puedes usar para muchas otras aplicaciones (webs, bases de datos, ...). Hemos aprendido a ejectuar notebooks dentro de contenedores (para lo cual necesitamos configurar los puertos y volúmenes adecuados), usar versiones optimizadas de `Pytorch` gracias al `NGC` de `NVIDIA` y crear nuestras propias imágenes con nuestro código y dependencias."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd3c0ff7553675f8399160a12fbc0c6054e9524c8e841ec60a211865d03cacc2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
