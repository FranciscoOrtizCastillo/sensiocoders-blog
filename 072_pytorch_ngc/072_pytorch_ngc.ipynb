{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff2464c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/072_pytorch_ngc/072_pytorch_ngc.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e829199e",
   "metadata": {},
   "source": [
    "# Pytorch NGC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f0058",
   "metadata": {},
   "source": [
    "En los posts anteriores hemos visto muchos trucos para optimizar nuestro c칩digo en Pytorch, sin embargo no nos hemos preocupado por la instalaci칩n del mismo. En este post vamos a aprender a usar una versi칩n de `Pytorch` optimizada que nos dar치 un extra de performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785f4f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T13:43:42.114525Z",
     "start_time": "2021-06-29T13:43:42.108116Z"
    }
   },
   "source": [
    "- https://ngc.nvidia.com/catalog/containers/nvidia:pytorch\n",
    "\n",
    "- https://docs.docker.com/engine/install/ubuntu/\n",
    "\n",
    "- https://github.com/NVIDIA/nvidia-docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb3823",
   "metadata": {},
   "source": [
    "  docker run --gpus all --ipc=host --rm -v local_dir:container_dir nvcr.io/nvidia/pytorch:xx.xx-py3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167539a",
   "metadata": {},
   "source": [
    "docker run --gpus all --ipc=host --rm  nvcr.io/nvidia/pytorch:21.06-py3 echo \"hola\"\n",
    "\n",
    "docker run --gpus all --ipc=host --rm  nvcr.io/nvidia/pytorch:21.06-py3 pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4a630",
   "metadata": {},
   "source": [
    "docker run --gpus all --ipc=host --rm -v $PWD/072_pytorch_ngc:/workspace  -p 8888:8888 nvcr.io/nvidia/pytorch:21.06-py3 jupyter notebook --allow-root --ip=0.0.0.0 --no-browser --NotebookApp.token=abc123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f25b53",
   "metadata": {},
   "source": [
    "```\n",
    "docker run --gpus all --ipc=host --rm -v $PWD/072_pytorch_ngc:/workspace -v $PWD/072_pytorch_ngc/data:/workspace/data  -p 8888:8888 nvcr.io/nvidia/pytorch:21.06-py3 jupyter notebook --allow-root --ip=0.0.0.0 --no-browser --NotebookApp.token=abc123\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e926c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0a0+c3d40fd'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540bac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20817bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images and labels ...\n",
      "Number of images: 27000\n",
      "Generating train / val splits ...\n",
      "Training samples:  21600\n",
      "Validation samples:  5400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def setup(path='./data', test_size=0.2, random_state=42):\n",
    "\n",
    "    classes = sorted(os.listdir(path))\n",
    "\n",
    "    print(\"Generating images and labels ...\")\n",
    "    images, encoded = [], []\n",
    "    for ix, label in enumerate(classes):\n",
    "        _images = os.listdir(f'{path}/{label}')\n",
    "        images += [f'{path}/{label}/{img}' for img in _images]\n",
    "        encoded += [ix]*len(_images)\n",
    "    print(f'Number of images: {len(images)}')\n",
    "\n",
    "     # train / val split\n",
    "    print(\"Generating train / val splits ...\")\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "        images,\n",
    "        encoded,\n",
    "        stratify=encoded,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(\"Training samples: \", len(train_labels))\n",
    "    print(\"Validation samples: \", len(val_labels))\n",
    "    \n",
    "    return classes, train_images, train_labels, val_images, val_labels\n",
    "\n",
    "classes, train_images, train_labels, val_images, val_labels = setup('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94311af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import io \n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        img = io.imread(self.images[ix])[...,(3,2,1)]\n",
    "        img = torch.tensor(img / 4000, dtype=torch.float).clip(0,1).permute(2,0,1)  \n",
    "        label = torch.tensor(self.labels[ix], dtype=torch.long)        \n",
    "        return img, label\n",
    "    \n",
    "ds = {\n",
    "    'train': Dataset(train_images, train_labels),\n",
    "    'val': Dataset(val_images, val_labels)\n",
    "}\n",
    "\n",
    "batch_size = 1024\n",
    "dl = {\n",
    "    'train': torch.utils.data.DataLoader(ds['train'], batch_size=batch_size, shuffle=True, num_workers=20, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(ds['val'], batch_size=batch_size, shuffle=False, num_workers=20, pin_memory=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da9a3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_outputs=10, use_amp=True):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet50(pretrained=True, progress=None)\n",
    "        self.model.fc = torch.nn.Linear(2048, n_outputs)\n",
    "        self.use_amp = use_amp\n",
    "\n",
    "    def forward(self, x, log=False):\n",
    "        if log:\n",
    "            print(x.shape)\n",
    "        with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "            return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b3d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def step(model, batch, device):\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_hat = model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    acc = (torch.argmax(y_hat, axis=1) == y).sum().item() / y.size(0)\n",
    "    return loss, acc\n",
    "\n",
    "def train_amp(model, dl, optimizer, epochs=10, device=\"cpu\", use_amp = True, prof=None, end=0):\n",
    "    model.to(device)\n",
    "    hist = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    for e in range(1, epochs+1):\n",
    "        # train\n",
    "        model.train()\n",
    "        l, a = [], []\n",
    "        bar = tqdm(dl['train'])\n",
    "        stop=False\n",
    "        for batch_idx, batch in enumerate(bar):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # AMP\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                loss, acc = step(model, batch, device)\n",
    "            scaler.scale(loss).backward()\n",
    "            # gradient clipping \n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            l.append(loss.item())\n",
    "            a.append(acc)\n",
    "            bar.set_description(f\"training... loss {np.mean(l):.4f} acc {np.mean(a):.4f}\")\n",
    "            # profiling\n",
    "            if prof:\n",
    "                if batch_idx >= end:\n",
    "                    stop = True\n",
    "                    break\n",
    "                prof.step()  \n",
    "        hist['loss'].append(np.mean(l))\n",
    "        hist['acc'].append(np.mean(a))\n",
    "        if stop:\n",
    "            break\n",
    "        # eval\n",
    "        model.eval()\n",
    "        l, a = [], []\n",
    "        bar = tqdm(dl['val'])\n",
    "        with torch.no_grad():\n",
    "            for batch in bar:\n",
    "                loss, acc = step(model, batch, device)\n",
    "                l.append(loss.item())\n",
    "                a.append(acc)\n",
    "                bar.set_description(f\"evluating... loss {np.mean(l):.4f} acc {np.mean(a):.4f}\")\n",
    "        hist['val_loss'].append(np.mean(l))\n",
    "        hist['val_acc'].append(np.mean(a))\n",
    "        # log\n",
    "        log = f'Epoch {e}/{epochs}'\n",
    "        for k, v in hist.items():\n",
    "            log += f' {k} {v[-1]:.4f}'\n",
    "        print(log)\n",
    "        \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3a0699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1153.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "training... loss 0.3993 acc 0.8690: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 22/22 [00:07<00:00,  3.06it/s]\n",
      "evluating... loss 3.7135 acc 0.6094: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 6/6 [00:01<00:00,  3.14it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss 0.3993 acc 0.8690 val_loss 3.7135 val_acc 0.6094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.1196 acc 0.9616: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 22/22 [00:04<00:00,  4.52it/s]\n",
      "evluating... loss 0.3278 acc 0.8983: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 6/6 [00:01<00:00,  3.19it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss 0.1196 acc 0.9616 val_loss 0.3278 val_acc 0.8983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.0657 acc 0.9797: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 22/22 [00:04<00:00,  4.45it/s]\n",
      "evluating... loss 0.1928 acc 0.9418: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 6/6 [00:01<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss 0.0657 acc 0.9797 val_loss 0.1928 val_acc 0.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "hist = train_amp(model, dl, optimizer, epochs=3, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8790c736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8b158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])torch.Size([16, 3, 32, 32])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "\n",
    "# cada gpu recibe la mitad del batch !\n",
    "output = model(torch.randn(32, 3, 32, 32).cuda(), log=True)\n",
    "\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5445ea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.5654 acc 0.8821: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 11/11 [00:04<00:00,  2.36it/s]\n",
      "evluating... loss 7.8633 acc 0.3981: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 3/3 [00:02<00:00,  1.11it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss 0.5654 acc 0.8821 val_loss 7.8633 val_acc 0.3981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.1449 acc 0.9560: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 11/11 [00:04<00:00,  2.46it/s]\n",
      "evluating... loss 0.8714 acc 0.8462: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 3/3 [00:02<00:00,  1.11it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss 0.1449 acc 0.9560 val_loss 0.8714 val_acc 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.0850 acc 0.9740: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 11/11 [00:04<00:00,  2.49it/s]\n",
      "evluating... loss 0.2223 acc 0.9453: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 3/3 [00:02<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss 0.0850 acc 0.9740 val_loss 0.2223 val_acc 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "dl = {\n",
    "    'train': torch.utils.data.DataLoader(ds['train'], batch_size=batch_size, shuffle=True, num_workers=20, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(ds['val'], batch_size=batch_size, shuffle=False, num_workers=20, pin_memory=True)\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "hist = train_amp(model, dl, optimizer, epochs=3, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42096cf",
   "metadata": {},
   "source": [
    "docker-compose up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ab883",
   "metadata": {},
   "source": [
    "docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f11ba",
   "metadata": {},
   "source": [
    "docker-compose down"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
