{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/076_pbdl_jax_cfd_intro/076_pbdl_jax_cfd_intro.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PBDL con JAX para CFD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Este es el primero en una serie de posts con un triple objetivo de aprendizaje, lo que significa aprender tres cosas a la vez ü§Ø (el tiempo es limitado y hay que optimizar). Seg√∫n el orden en el que aparecen en el t√≠tulo:\n",
    "\n",
    "- [**PBDL**](https://physicsbaseddeeplearning.org/intro.html): *Physics-Based Deep Learning*, o el uso del *Deep Learning* (redes neuronales) para simulaci√≥n f√≠sica. \n",
    "- [**JAX**](https://github.com/google/jax): Una librer√≠a para computaci√≥n num√©rica, con especial √©nfasis en Inteligencia Artificial.\n",
    "- [**CFD**](https://es.wikipedia.org/wiki/Mec%C3%A1nica_de_fluidos_computacional): *Computational Fluid Dynamics*, el campo de la f√≠sica que se enfoca en la simulaci√≥n de fluidos para aplicaciones de aerodin√°mica, combusti√≥n, etc.\n",
    "\n",
    "Si te interesa aprender sobre cualquiera de estos tres temas (los cuales por si solos merecen de gran atenci√≥n), estas en el lugar adecuado üôÉ Sin embargo, te advierto que nos vamos a alejar del *machine learning* tradicional para explorar un nuevo campo, el del uso de las redes neuronales para aproximar soluciones a ecuaciones diferenciales. Es posible que en algunos momentos te preguntes: ¬øes esto realmente *machine learning*? Te entiendo. A√∫n as√≠, creo firmemente que el campo del *PBDL* revolucionar√° la manera en la que simulamos la naturaleza en los pr√≥ximos a√±os, de la misma manera que el *Deep Learning* ha revolucionado (y lo sigue haciendo) tantos otros campos de la ciencia, como por ejemplo el [plegado de proteinas](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Physics-based Deep Learning*\n",
    "\n",
    "El campo del *PBDL* es una disciplina relativamente nueva e inexplorada que se basa el uso de redes neuronales para sustituir (o complementar) m√©todos num√©ricos \"tradicionales\" utilizados desde hace a√±os para simular los diferentes procesos f√≠sicos que rigen nuestra naturaleza (desde el comportamiento de nuestra atm√≥sfera hasta el movimiento de estrellas y galaxias). Estos procesos pueden ser descritos, en la mayor√≠a de ocasiones, mediante ecuaciones matem√°ticas. Resolver estas ecuaciones nos permite calcular, por ejemplo, la distribuci√≥n de presi√≥n sobre una superficie aerodin√°mica (lo cual es muy √∫til a la hora de dise√±ar aviones m√°s eficientes, entre muchas otras aplicaciones). Sin embargo, como te podr√°s imaginar, estas ecuaciones suelen ser muy dif√≠ciles de resolver y, en la mayor√≠a de situaciones, ni siquiera pueden ser resueltas de manera anal√≠tica. Es aqu√≠ donde entran en juego los m√©todos num√©ricos, t√©cnicas que nos permiten aproximar soluciones a estas ecuaciones que si bien no son exactas son lo suficientemente precisas para su uso en aplicaciones reales. Tradicionalmente, m√©todos num√©ricos de este estilo requieren de grandes recursos computacionales (es por este motivo que tenemos \"superordenadores\"). Por lo que cualquier avance en el campo que nos permita encontrar soluciones m√°s r√°pidas y baratas supone una revoluci√≥n. Creo que el campo del *PBDL* ser√° la siguiente revoluci√≥n en este campo. De hecho, este fue el motivo por el que me adentr√© en el mundo del *Deep Learning*, persiguiendo la idea de que usar [redes neuronales para aproximar soluciones a ecuaciones diferenciales](https://arxiv.org/abs/1912.04737) pod√≠a ser una buena idea.\n",
    "\n",
    "> Recientemente se ha publicado este [libro](https://physicsbaseddeeplearning.org/intro.html) sobre *PBDL*. No dudes en consultarlo para aprender m√°s !"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Computational Fluid Dynamics*\n",
    "\n",
    "Dentro del gran abanico de aplicaciones de la f√≠sica computacional, la mec√°nica de fluidos computacional se encarga del estudio del comportamiento de fluidos, principalmente mediante la resoluci√≥n de las ecuaciones de [Navier-Stokes](https://es.wikipedia.org/wiki/Ecuaciones_de_Navier-Stokes). Esto tiene un uso muy importante en el dise√±o de aeronaves, coches (muy importante en coches el√©ctricos), previsi√≥n meteorol√≥gica y an√°lisis de la evoluci√≥n de contaminantes, etc. \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/X-43A_%28Hyper_-_X%29_Mach_7_computational_fluid_dynamic_%28CFD%29.jpg/1024px-X-43A_%28Hyper_-_X%29_Mach_7_computational_fluid_dynamic_%28CFD%29.jpg)\n",
    "\n",
    "Como ya he comentado anteriormente, resolver estas ecuaciones de manera anal√≠tica es imposible y su resoluci√≥n num√©rica require de grandes recursos computacionales. A√∫n as√≠, cada vez es m√°s extendido su uso. En el caso del sector aeron√°utico la alternativa es el uso de t√∫neles de viento, lo cual es todav√≠a m√°s caro y lento. Poder dise√±ar veh√≠culos con software de dise√±o 3d por ordenador, simular su comportamiento en varias condiciones e iterar su dise√±o hasta encontrar la geometr√≠a √≥ptima en entornos virtuales es una gran ventaja. Creo que el uso del *Deep Learning* para *CFD* supondr√° una revoluci√≥n y acelerar√°, a la vez que abaratar√°, todo este proceso dando como resultado veh√≠culos m√°s eficientes, que viajen m√°s r√°pido consumiendo y contaminando menos. \n",
    "\n",
    "> Si quieres aprender m√°s sobre *CFD* te recomiendo echarle un vistazo a mi [tesis doctoral](https://www.tesisenred.net/handle/10803/667041#page=1) ü§ó"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## JAX\n",
    "\n",
    "Para explorar el mundo del *PBDL* para *CFD* usaremos la librer√≠a [JAX](https://github.com/google/jax). Desarrollada y mantenida por Google, JAX es una librer√≠a para c√°lculo num√©rico en Python con un enfoque particular en *machine learning*, ya que nos va a permitir calcular derivadas de forma autom√°tica y ejecutar nuestras operaciones en GPUs y TPUs de manera sencilla. Similar en esp√≠ritu a Tensorflow y Pytorch, la principal diferencia de JAX es su API minimalista y sencilla."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instalaci√≥n\n",
    "\n",
    "Para instalar JAX puedes seguir la [instrucciones](https://github.com/google/jax#installation) en Github. La versi√≥n en CPU la puedes instalar en Ubuntu, MacOS y Windows. La versi√≥n GPU solo la podr√°s instalar en Ubuntu, donde necesitar√°s tener instalado CUDA y CUDNN. En Google Colab, ya lo tendr√°s instalado y listo para ser usado tanto en CPU, GPU y TPU. Una vez instalado, puedes probar que todo est√° bien."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import jax\n",
    "\n",
    "jax.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'0.2.21'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conceptos b√°sicos\n",
    "\n",
    "Lo primero que tienes que saber acerca de JAX es que es muy similar a NumPy, por lo que lo podr√°s usar para lo mismo (m√°s algunos beneficios que veremos m√°s adelante). Uno de los usos principales de NumPy, que usaremos mucho a la hora de simular fluidos y que tambi√©n se usa a la hora de entrenar redes neuronales, es la multiplicaci√≥n de matrices. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# esto es un vector\n",
    "\n",
    "x = jnp.arange(3)\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([0, 1, 2], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# esto es una matriz\n",
    "\n",
    "I = jnp.eye(3)\n",
    "I"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[1., 0., 0.],\n",
       "             [0., 1., 0.],\n",
       "             [0., 0., 1.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# multiplicaci√≥n matriz-vector \n",
    "\n",
    "I @ x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([0., 1., 2.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transformaciones\n",
    "\n",
    "El concepto de `transformaciones` es lo que le da a JAX su flexibilidad y potencia. Estos son algunos ejemplos:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "def func(size=1000):\n",
    "  x = jnp.arange(size)\n",
    "  I = jnp.eye(size)\n",
    "  return I @ x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "%timeit func()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "993 ¬µs ¬± 28.4 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con `jit` aceleraremos nuestros c√°lculos gracias al *just-in-time compiler*."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "from jax import jit\n",
    "\n",
    "func_jit = jit(func)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "%timeit func_jit()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46.5 ¬µs ¬± 374 ns per loop (mean ¬± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con `grad` podremos calcular derivadas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "def func2(x):\n",
    "  return x**2.\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "x = jnp.arange(3.)\n",
    "\n",
    "func2(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([0., 1., 4.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from jax import grad\n",
    "\n",
    "derivative_fn = grad(func2)\n",
    "\n",
    "derivative_fn(10.)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray(20., dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con `vmap` podremos auto-vectorizar nuestro c√≥digo, sin tener que preocuparnos por pensar como pasar nuestros c√°lculos a modo \"batch\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "def func3(x):\n",
    "  I = jnp.eye(x.size)\n",
    "  return I @ x\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "x = jnp.arange(3)\n",
    "\n",
    "func3(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([0., 1., 2.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "x_batch = jnp.stack(3*[x])\n",
    "\n",
    "x_batch"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[0, 1, 2],\n",
       "             [0, 1, 2],\n",
       "             [0, 1, 2]], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "func3(x_batch) # esto no va porque las dimensiones no encajan"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got [9] and [3].",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33437/764660429.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfunc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# esto no va porque las dimensiones no encajan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_33437/2536116267.py\u001b[0m in \u001b[0;36mfunc3\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   6551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_accepted_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6552\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6553\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6554\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeferring_binary_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   4829\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_squeeze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4830\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_squeeze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4831\u001b[0;31m   out = lax.dot_general(\n\u001b[0m\u001b[1;32m   4832\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb_is_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4833\u001b[0m     precision=precision)\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   3435\u001b[0m     msg = (\"dot_general requires contracting dimensions to have the same \"\n\u001b[1;32m   3436\u001b[0m            \"shape, got {} and {}.\")\n\u001b[0;32m-> 3437\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs_contracting_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_contracting_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_dot_general_shape_computation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_numbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got [9] and [3]."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from jax import vmap \n",
    "\n",
    "func_vmap = vmap(func3)\n",
    "\n",
    "func_vmap(x_batch)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[0., 1., 2.],\n",
       "             [0., 1., 2.],\n",
       "             [0., 1., 2.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Existen otras transformaciones que pueden ser √∫tiles, adem√°s las podemos combinar de manera arbitraria. Todo esto lo iremos aprendiendo en posts futuros."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dd3c0ff7553675f8399160a12fbc0c6054e9524c8e841ec60a211865d03cacc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}