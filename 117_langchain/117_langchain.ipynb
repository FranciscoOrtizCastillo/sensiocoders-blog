{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/117_langchain/117_langchain.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 🦜🔗"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el despegue de los modelos de lenguaje que estamos viviendo en este momento cientos de nuevas herramientas y aplicaciones están apareciendo para aprovechar el poder de estas redes neuronales. Una de ellas parece destacar por encima del resto, y ésta es [LangChain](https://docs.langchain.com/docs/). En este post vamos a ver qué es y cómo podemos usarla."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es LangChain?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según su [documentación](https://docs.langchain.com/docs/), Langchain es un entorno de desarrollo de aplicaciones basadas en modelos de lenguajes. Las herramientas proporcionadas por LangChain permiten, por un lado, conectar modelos de lenguaje con otras fuentes de datos (como por ejemplo tus porpios documentos, bases de datos o emails) y, por otro lado, permitir a estos modelos interactuar con su entorno (por ejemplo, enviando emails o llamando a APIs web). Langchain ofrece librerías en Python y Javascript para facilitar el desarrollo de estas aplicaciones, en este post nos centraremos en la librería de Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un ejemplo práctico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos viendo un ejemplo práctico de cómo usar LangChain para proporcionar información sobre un documento, y luego entraremos en detalle de los diferentes componentes y cómo funcionan.\n",
    "\n",
    "> Vamos a usar como documento el artículo [On the Measure of Intelligence](https://arxiv.org/pdf/1911.01547.pdf), de François Chollet (2019)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que necesitamos es instalar la librería de LangChain:\n",
    "\n",
    "```bash\n",
    "pip install langchain\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.160'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1911.01547.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "pdfs = glob('*.pdf')\n",
    "pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='9 1 0 2\\n\\nv o N 5 2\\n\\n] I\\n\\nA . s c [\\n\\n2 v 7 4 5 1 0 . 1 1 9 1 : v i X r a\\n\\nOn the Measure of Intelligence\\n\\nFranc¸ois Chollet ∗ Google, Inc. fchollet@google.com\\n\\nNovember 5, 2019\\n\\nAbstract\\n\\nTo make deliberate progress towards more intelligent and more human-like artiﬁcial systems, we need to be following an appropriate feedback signal: we need to be able to deﬁne and evaluate intelligence in a way that enables comparisons between two systems, as well as comparisons with humans. Over the past hundred years, there has been an abun- dance of attempts to deﬁne and measure intelligence, across both the ﬁelds of psychology and AI. We summarize and critically assess these deﬁnitions and evaluation approaches, while making apparent the two historical conceptions of intelligence that have implicitly guided them. We note that in practice, the contemporary AI community still gravitates to- wards benchmarking intelligence by comparing the skill exhibited by AIs and humans at speciﬁc tasks, such as board games and video games. We argue that solely measuring skill at any given task falls short of measuring intelligence, because skill is heavily modulated by prior knowledge and experience: unlimited priors or unlimited training data allow ex- perimenters to “buy” arbitrary levels of skills for a system, in a way that masks the system’s own generalization power. We then articulate a new formal deﬁnition of intelligence based on Algorithmic Information Theory, describing intelligence as skill-acquisition efﬁciency and highlighting the concepts of scope, generalization difﬁculty, priors, and experience, as critical pieces to be accounted for in characterizing intelligent systems. Using this deﬁ- nition, we propose a set of guidelines for what a general AI benchmark should look like. Finally, we present a new benchmark closely following these guidelines, the Abstraction and Reasoning Corpus (ARC), built upon an explicit set of priors designed to be as close as possible to innate human priors. We argue that ARC can be used to measure a human-like form of general ﬂuid intelligence and that it enables fair general intelligence comparisons between AI systems and humans.\\n\\n∗I thank Jos´e Hern´andez-Orallo, Julian Togelius, Christian Szegedy, and Martin Wicke for their valuable com-\\n\\nments on the draft of this document.\\n\\n1\\n\\nContents\\n\\nI Context and history\\n\\nI.2.1 I.2.2\\n\\nI.1 Need for an actionable deﬁnition and measure of intelligence . . . . . . . . . . . . . . . . . . . . . . . . . I.2 Deﬁning intelligence: two divergent visions . . . . . . . . . . . . Intelligence as a collection of task-speciﬁc skills Intelligence as a general learning ability . . . . . . . . . . . . . . . . . I.3 AI evaluation: from measuring skills to measuring broad abilities . . . . . . Skill-based, narrow AI evaluation . . . . . . . . . . . . . . . . . . . . The spectrum of generalization: robustness, ﬂexibility, generality . . .\\n\\nI.3.1 I.3.2 I.3.3 Measuring broad abilities and general intelligence: the psychometrics\\n\\n3 3 4 5 6 7 7 9\\n\\n.\\n\\n.\\n\\n. . . . . .\\n\\n. . . . . . . . . . . . . . . . . . . . . . . 13 perspective . . . . . . . . . . . . . . . 14 Integrating AI evaluation and psychometrics Current trends in broad AI evaluation . . . . . . . . . . . . . . . . . . 16\\n\\nI.3.4 I.3.5\\n\\nII A new perspective\\n\\nII.1 Critical assessment .\\n\\n.\\n\\n18 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n\\nII.1.1 Measuring the right thing: evaluating skill alone does not move us\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\nII.1.2 II.1.3\\n\\nforward . The meaning of generality: grounding the g factor Separating the innate from the acquired: insights from developmental psychology .\\n\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 . . . . . . . . . . . 20\\n\\n. . . . . . . . . . . . . . . . . . . . . . . 24 II.2 Deﬁning intelligence: a formal synthesis . . . . . . . . . . . . . . . . . . . 27 Intelligence as skill-acquisition efﬁciency . . . . . . . . . . . . . . . . 27', metadata={'source': '/tmp/tmpgtp6ichu'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import OnlinePDFLoader\n",
    "\n",
    "loader = OnlinePDFLoader(\"https://arxiv.org/pdf/1911.01547.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindexes\u001b[39;00m \u001b[39mimport\u001b[39;00m VectorstoreIndexCreator\n\u001b[0;32m----> 2\u001b[0m index \u001b[39m=\u001b[39m VectorstoreIndexCreator()\u001b[39m.\u001b[39mfrom_loaders([loader])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/main.py:1066\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/fields.py:439\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField.get_default\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device has 2 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=\"bigscience/bloom-1b7\", task=\"text-generation\", model_kwargs={\"temperature\":0, \"max_length\":64})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (64) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First, we need to understand what is an electroencephalogram. An electroencephalogram is a recording of brain activity. It is a recording of brain activity that is made by placing electrodes on the scalp. The electrodes are placed\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate,  LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Data loading](https://python.langchain.com/en/latest/modules/indexes/document_loaders.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
